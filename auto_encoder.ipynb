{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora, models, similarities, downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/taru/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading word2vec model\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading word2vec model\")\n",
    "word2vec_model = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToVector(word, model):\n",
    "    try:\n",
    "        return model[word]\n",
    "    except KeyError:\n",
    "        # Handle out-of-vocabulary words\n",
    "        return np.zeros(model.vector_size)  # Return zero vector for OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToVectors(text, model):\n",
    "    tokens = tokenize(text)  # Tokenize the text\n",
    "    vectors = [wordToVector(token, model) for token in tokens]  # Convert words to vectors\n",
    "    vectors = np.array(vectors)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a skip connection auto-encoder architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnectionEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, compression_size):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Assuming the embeddings are of dimensions 300 and each sentence has 10 words/tokens\n",
    "        num_of_words = input_shape[0]\n",
    "        embedding_dim = input_shape[1]\n",
    "\n",
    "        # Calculate the input size for the MLP\n",
    "        mlp_input_size = embedding_dim * num_of_words\n",
    "\n",
    "        # Define layers for the encoder\n",
    "        self.layer1 = nn.Linear(mlp_input_size, 2400)\n",
    "        self.layer2 = nn.Linear(2400, 1500)\n",
    "        self.layer3 = nn.Linear(1500, compression_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        # Flatten the input features\n",
    "        features_flat = features.flatten()\n",
    "\n",
    "        features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
    "        \n",
    "        # Pass through the first layer\n",
    "        out1 = self.layer1(features_flat)\n",
    "        a1 = self.relu(out1)\n",
    "        \n",
    "        # Pass through the second layer\n",
    "        out2 = self.layer2(a1)\n",
    "        a2 = self.relu(out2)\n",
    "\n",
    "        # Pass through the third layer\n",
    "        out3 = self.layer3(a2)\n",
    "    \n",
    "        # Return the outputs of each layer\n",
    "        return out3, out2, out1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnectionDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        # Assuming the embeddings are of dimensions 300 and each sentence has 10 words/tokens\n",
    "        num_of_words = output_shape[0]\n",
    "        embedding_dim = output_shape[1]\n",
    "\n",
    "        # Calculate the output size for the MLP\n",
    "        mlp_output_size = embedding_dim * num_of_words\n",
    "\n",
    "        # Define layers for the decoder\n",
    "        self.layer1 = nn.Linear(input_size, 1500)\n",
    "        self.layer2 = nn.Linear(1500, 2400)\n",
    "        self.layer3 = nn.Linear(2400, mlp_output_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "\n",
    "        # Pass through the first layer\n",
    "        out1 = self.layer1(x1)\n",
    "        a1 = self.relu(out1)\n",
    "\n",
    "        # Skip connection: add input from previous layer and pass through the second layer\n",
    "        out2 = self.layer2(a1 + x2)\n",
    "        a2 = self.relu(out2)\n",
    "\n",
    "        # Skip connection: add input from previous layer and pass through the third layer\n",
    "        out3 = self.layer3(a2 + x3)\n",
    "\n",
    "        # Reshape the final output into a 300-dimensional embedding for 10 words\n",
    "        out = out3.view(13, 300)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, compression_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_shape\n",
    "\n",
    "        self.encoder = SkipConnectionEncoder(input_shape, compression_size)\n",
    "        self.decoder = SkipConnectionDecoder(compression_size, input_shape)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        # implementing auto-encoder.\n",
    "        \n",
    "        encoded, _ , _ = self.encoder(features)\n",
    "        activatedEncoded = self.relu(encoded)\n",
    "        # in order to implement variational auto-encoders, the forward pass should return the mean and the variance as well.\n",
    "        # this will in turn be passed to the loss function which uses them to calculate the kl divergence.\n",
    "        decoded = self.decoder(activatedEncoded, 0, 0)\n",
    "\n",
    "        # out1 is the output for the encoder, out2 is the output for the decoder.\n",
    "        \n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 300)\n",
      "tensor([[-0.0283,  0.0053, -0.0251,  ...,  0.0180, -0.0127,  0.0172],\n",
      "        [-0.0123, -0.0030, -0.0252,  ...,  0.0038,  0.0143, -0.0114],\n",
      "        [-0.0005,  0.0066,  0.0160,  ..., -0.0108, -0.0147,  0.0153],\n",
      "        ...,\n",
      "        [ 0.0019, -0.0104,  0.0061,  ..., -0.0144, -0.0100, -0.0185],\n",
      "        [ 0.0156, -0.0135, -0.0190,  ..., -0.0001,  0.0024, -0.0048],\n",
      "        [-0.0111, -0.0171,  0.0168,  ..., -0.0294, -0.0014,  0.0034]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([13, 300])\n",
      "tensor([ 2.8519e-02, -2.1042e-02, -1.8555e-02, -5.5807e-03,  1.2468e-02,\n",
      "         2.2315e-03,  2.0965e-03, -1.2499e-03,  6.0861e-03,  1.5911e-02,\n",
      "         4.1068e-02, -1.8818e-02, -2.7332e-02, -5.0532e-02,  4.3839e-02,\n",
      "        -1.9399e-02,  2.3222e-02, -1.2101e-02,  2.7841e-03,  1.4913e-03,\n",
      "        -1.2275e-03,  3.0557e-02, -1.7421e-02,  2.2639e-02,  1.0563e-02,\n",
      "         2.1042e-02,  6.2973e-04, -1.8636e-02,  1.7675e-02, -6.6244e-03,\n",
      "         1.8061e-02, -6.6992e-03,  6.7019e-03,  1.3053e-02,  1.7658e-02,\n",
      "         3.7380e-02, -1.6891e-02, -2.6380e-02, -1.8936e-02,  1.3240e-02,\n",
      "         9.0916e-03,  1.1161e-02, -6.8484e-03,  3.9809e-02,  6.0411e-03,\n",
      "         2.5509e-02,  1.1381e-02,  6.2302e-03,  5.8855e-02,  1.5748e-02,\n",
      "         2.6156e-02,  9.3465e-03,  2.7095e-02, -2.3945e-02,  3.2959e-03,\n",
      "         4.1442e-03,  2.2139e-02, -3.0705e-02,  1.8679e-02, -2.0755e-02,\n",
      "        -3.3727e-03, -2.2855e-02, -7.9006e-03,  3.0953e-04,  9.2053e-03,\n",
      "         9.3972e-03, -9.1737e-03, -2.1784e-03, -1.3505e-03,  2.4377e-03,\n",
      "         2.0063e-02, -7.7486e-03,  6.2602e-03, -3.5614e-02,  1.3931e-02,\n",
      "        -1.8330e-02,  1.3256e-02,  1.0165e-02,  2.3672e-02, -3.0282e-02,\n",
      "         6.2950e-03,  4.1890e-02,  5.4291e-03,  8.4132e-03,  2.1548e-02,\n",
      "         1.0161e-02, -1.3827e-02,  2.1949e-02, -3.1360e-02,  1.0419e-02,\n",
      "        -8.5274e-05, -2.2766e-03, -9.2469e-03, -8.0912e-03, -2.7227e-02,\n",
      "         6.5604e-03,  2.2551e-02,  5.0979e-02,  4.3005e-02, -3.8485e-03,\n",
      "        -1.8702e-02,  2.2414e-03, -3.8240e-02,  2.1237e-02, -1.8105e-02,\n",
      "         1.6581e-02,  4.3471e-02, -2.2565e-02, -2.6199e-02,  9.5522e-03,\n",
      "         2.2580e-03, -3.5142e-02, -4.0165e-03, -1.9947e-02, -1.2960e-02,\n",
      "        -2.5441e-02,  3.3323e-02, -5.3162e-03, -4.7492e-03,  1.2088e-02,\n",
      "         3.9539e-05, -2.0188e-02,  1.7075e-02,  1.8700e-03, -1.8880e-02,\n",
      "         8.9699e-03, -9.1897e-03, -1.9917e-02,  8.0933e-03,  1.6043e-02,\n",
      "        -3.6127e-03,  1.3248e-02,  2.2671e-02,  2.8316e-02, -1.9964e-02,\n",
      "         1.6471e-02,  4.3035e-03, -7.8260e-03,  1.8464e-02, -2.3888e-02,\n",
      "        -3.6254e-02,  1.9311e-02, -1.6994e-02,  2.3330e-02, -1.8488e-02,\n",
      "         3.8419e-02, -1.2055e-02, -1.6938e-02,  2.6043e-02, -3.2321e-03,\n",
      "        -9.5682e-04, -5.6346e-03, -1.3194e-02,  3.2152e-02, -3.0390e-02,\n",
      "         1.8515e-02, -2.6147e-02,  1.5302e-02, -3.0594e-02, -1.2387e-02,\n",
      "         3.5734e-02,  2.4153e-02, -2.9981e-02,  1.8679e-03,  8.9285e-03,\n",
      "         1.7552e-02, -5.6615e-03, -7.5287e-03,  2.3124e-03,  2.4236e-02,\n",
      "         7.3635e-03,  8.9409e-03, -1.9631e-03,  7.3508e-04,  1.9195e-02,\n",
      "         9.6126e-03,  3.5346e-02,  2.6765e-02, -1.9008e-02,  1.2409e-02,\n",
      "        -3.9594e-03, -4.4963e-03, -5.7752e-03, -2.9270e-02, -1.8468e-02,\n",
      "         4.4731e-03, -8.3967e-03,  6.6557e-02, -2.5300e-02, -1.7871e-02,\n",
      "         9.1080e-03,  5.5587e-03,  3.6835e-02, -2.4348e-02,  1.2775e-02,\n",
      "         1.8679e-02, -3.5071e-02,  8.2633e-03, -5.5966e-03,  7.5799e-03,\n",
      "        -1.5347e-02, -1.0551e-02, -1.9378e-02,  1.5046e-02, -2.9299e-02,\n",
      "         9.6479e-03, -1.5571e-02, -1.0455e-02,  1.4292e-02,  1.4399e-03,\n",
      "        -1.4790e-02, -4.2107e-03,  1.1856e-02,  1.3091e-02,  6.9866e-03,\n",
      "         3.3118e-02,  4.4720e-03,  1.0205e-02,  8.2467e-03,  1.4594e-02,\n",
      "        -7.0856e-03,  3.1206e-02, -1.8913e-02,  1.5017e-02,  4.9200e-04,\n",
      "         1.5317e-02, -2.0284e-02,  3.5286e-02, -1.3849e-02,  1.5269e-02,\n",
      "         2.6493e-02, -4.4134e-02,  2.2889e-02, -5.0496e-03, -1.3567e-02,\n",
      "         1.4280e-02,  3.3531e-03, -1.4932e-02, -3.6713e-02, -3.9717e-05,\n",
      "        -2.1028e-02,  2.8663e-03, -1.5083e-02,  2.2286e-02, -4.4149e-03,\n",
      "        -2.0559e-02,  1.5765e-02, -3.5085e-02, -2.7551e-03, -1.7568e-02,\n",
      "        -2.8722e-04,  1.7030e-02, -2.0851e-02, -5.0374e-02,  4.3365e-02,\n",
      "         1.0107e-02,  4.3891e-02,  5.3720e-02,  2.3706e-03,  1.6990e-02,\n",
      "         1.7487e-02, -6.6297e-03,  1.7344e-02,  3.5309e-02,  9.9453e-04,\n",
      "        -2.1155e-02, -1.6407e-02, -2.9186e-02, -7.9633e-03, -8.1668e-03,\n",
      "         3.2746e-02,  5.4923e-02, -5.1989e-03,  1.5619e-03,  1.9560e-02,\n",
      "        -2.7602e-02,  9.5948e-03,  9.2336e-03, -1.8532e-02, -1.7535e-02,\n",
      "         1.3493e-02,  3.7414e-02, -1.6110e-02, -5.2973e-02,  4.7298e-03,\n",
      "        -2.4325e-02, -2.5152e-02, -3.1066e-02,  2.2620e-02,  7.6699e-03,\n",
      "        -2.1714e-02,  2.4325e-03, -1.4161e-02,  4.1791e-03,  1.9938e-02,\n",
      "        -3.3937e-02, -1.2023e-02,  1.4759e-02, -1.3011e-02,  2.3208e-03,\n",
      "        -3.3304e-03, -4.1914e-02, -2.0881e-02, -9.8311e-03,  1.0230e-03,\n",
      "        -3.6996e-03, -9.4940e-03,  1.5719e-02,  9.4771e-04, -2.0393e-02,\n",
      "         3.4866e-03,  4.7315e-02,  3.1924e-02, -9.2641e-03, -2.6580e-02,\n",
      "        -8.6165e-03, -2.3537e-02, -1.0363e-03, -1.4137e-02, -7.8755e-03,\n",
      "         4.6693e-02, -1.6921e-02,  3.1939e-02, -1.2391e-02,  4.4815e-04,\n",
      "         1.2630e-02, -3.5959e-02, -1.7148e-02,  2.2476e-02, -1.8048e-02,\n",
      "        -2.7437e-02,  5.1899e-02, -6.5869e-03, -2.1501e-02,  1.9291e-02,\n",
      "         1.4145e-03,  2.8611e-02, -1.9707e-02,  1.4219e-02, -2.2936e-02,\n",
      "        -9.3164e-03, -4.1946e-03,  2.0016e-02,  2.9511e-02, -9.5424e-03,\n",
      "         7.1682e-03,  1.2873e-02, -1.7187e-02,  2.4159e-02,  3.0290e-03,\n",
      "        -8.1641e-03, -3.1904e-03,  7.5864e-03,  3.9687e-02,  2.4947e-02,\n",
      "         1.7227e-02, -3.0926e-02, -4.0436e-04, -2.7336e-02, -3.6029e-02,\n",
      "         1.7046e-02,  2.3628e-02, -5.3400e-03, -2.2648e-03,  1.4773e-02,\n",
      "        -6.0832e-03,  1.7213e-04,  2.8393e-03,  8.8745e-03,  1.1330e-02,\n",
      "         1.0493e-02, -2.9089e-02,  3.9265e-03, -5.6296e-03, -2.5275e-03,\n",
      "         1.7960e-02, -2.6584e-03,  1.3930e-02,  1.1368e-02, -4.8690e-03,\n",
      "        -2.3686e-02, -3.1888e-02, -1.5150e-02, -1.7451e-02, -2.4437e-03,\n",
      "        -4.2913e-03,  1.3852e-02,  1.3935e-02, -1.4132e-03, -3.4866e-05,\n",
      "        -8.1080e-03, -1.2779e-03, -1.9826e-02,  1.2014e-02,  1.9193e-02,\n",
      "         2.5975e-03, -4.6099e-02,  7.5947e-03, -6.7655e-03, -6.8035e-03,\n",
      "         3.3007e-04, -1.1895e-03,  2.9259e-02,  1.3206e-02, -2.0631e-02,\n",
      "        -2.3869e-02, -3.3348e-02,  6.1650e-03, -1.6570e-02, -3.3610e-03,\n",
      "         5.6917e-03, -2.4462e-02,  1.7779e-02, -7.6525e-03, -6.2138e-03,\n",
      "        -2.3530e-02,  3.0645e-02,  5.7897e-03,  3.4921e-03, -9.8656e-03,\n",
      "         3.6335e-02,  2.0579e-02, -3.0614e-02, -3.2394e-02,  2.4972e-02,\n",
      "        -1.3385e-02,  1.3592e-02,  2.9553e-03, -3.2575e-02, -8.1684e-03,\n",
      "         3.8815e-02, -9.2878e-03,  3.0471e-02,  3.7945e-02, -1.6832e-02,\n",
      "        -3.3964e-02, -1.7674e-02,  1.8428e-03, -3.7813e-02, -2.9826e-02,\n",
      "         4.1132e-02, -4.5486e-03, -1.0840e-02,  3.3291e-02, -1.6810e-02,\n",
      "        -8.9762e-03,  3.0271e-02, -1.0752e-02, -3.8762e-04,  3.8352e-03,\n",
      "         3.4376e-02, -3.9239e-03,  1.5053e-03, -1.7192e-02, -4.9467e-03,\n",
      "        -2.0605e-02, -1.2273e-02, -1.7494e-03,  1.8052e-02,  8.2339e-03,\n",
      "        -1.3992e-02,  1.4670e-02, -3.2966e-02,  3.5237e-02,  3.2608e-02,\n",
      "        -2.9868e-02, -1.3659e-03,  2.9639e-02, -4.9196e-03,  1.6148e-02,\n",
      "        -8.1568e-04, -1.7852e-02, -1.9077e-02,  1.5518e-03,  1.2587e-02,\n",
      "        -2.3222e-03,  2.9347e-03,  3.5816e-02,  3.7671e-02,  2.6034e-02,\n",
      "         2.4643e-02, -3.2380e-03, -1.7412e-03, -1.5168e-02,  2.7189e-03,\n",
      "        -2.7237e-02,  3.9742e-02,  8.0429e-03,  2.7344e-02, -3.4800e-02,\n",
      "         3.1051e-02, -1.6670e-02, -1.4627e-02, -1.5229e-02,  7.6250e-03,\n",
      "        -1.1493e-02, -5.4492e-03, -1.1062e-02, -1.8983e-04,  3.2035e-03,\n",
      "         2.4476e-02,  6.3378e-03, -1.0558e-02, -1.6169e-02,  3.8310e-02,\n",
      "        -2.2304e-02,  1.0671e-02,  8.9001e-04,  7.6006e-03,  1.9011e-02,\n",
      "         2.9693e-02,  5.4807e-03,  2.8108e-02,  2.2894e-02,  4.5939e-02,\n",
      "         6.9959e-03, -5.1015e-03,  9.0513e-03, -1.1091e-02,  6.2804e-02,\n",
      "        -1.5694e-02,  3.9695e-02,  5.1686e-03, -2.4768e-02, -8.0031e-03,\n",
      "         2.7395e-02, -2.5039e-02, -3.7186e-02,  8.9660e-03,  2.0713e-02,\n",
      "        -3.0258e-02,  4.1583e-03, -8.6287e-03,  2.2969e-02, -7.9262e-03,\n",
      "        -2.6591e-03,  1.8309e-02, -9.0492e-03, -3.9713e-03,  2.8348e-02,\n",
      "        -3.7022e-02,  2.0811e-02,  2.1094e-02,  3.8469e-02, -8.4191e-03,\n",
      "        -1.2767e-02,  9.0753e-03,  1.4214e-02,  1.6699e-02,  5.7498e-03,\n",
      "        -1.1170e-03, -2.0289e-02, -1.1024e-02, -3.2397e-03,  3.7358e-02,\n",
      "        -2.5167e-02,  4.0531e-02,  1.3228e-02, -1.9765e-02,  6.4211e-03,\n",
      "        -2.8512e-02, -1.3545e-02,  1.5006e-03,  2.5231e-02, -4.2316e-02,\n",
      "         3.1097e-03,  7.9266e-03,  1.1297e-02,  2.6231e-02,  4.7734e-02,\n",
      "         2.5836e-02, -3.2689e-03,  1.5095e-02,  1.2671e-02,  2.2317e-02,\n",
      "         4.0040e-02, -5.1896e-03,  3.5320e-02, -2.5985e-02, -1.5335e-02,\n",
      "        -1.7188e-02, -2.9971e-02, -1.4545e-02, -2.7584e-03, -5.6631e-02,\n",
      "         2.2954e-02, -4.8666e-03,  3.2594e-02,  2.2651e-03, -1.7408e-02,\n",
      "        -8.4191e-03, -1.8093e-02, -1.6529e-02,  2.1704e-04,  9.5096e-03,\n",
      "        -4.5701e-03, -6.9540e-03,  8.8207e-03, -1.4830e-02, -6.7970e-04,\n",
      "         1.9119e-02, -2.3429e-02,  3.1621e-02, -1.2439e-02,  3.3033e-03,\n",
      "         7.2160e-03, -2.5937e-02, -1.3273e-02,  4.3455e-03, -3.5442e-02,\n",
      "         1.5743e-02, -7.6886e-03, -1.1541e-02, -1.1656e-03, -1.8679e-03,\n",
      "        -2.2815e-02,  9.9522e-03, -1.3872e-02, -4.7618e-03,  3.9171e-02,\n",
      "         4.7902e-03, -1.9640e-02,  6.6283e-04, -8.2001e-03,  7.6356e-04,\n",
      "        -2.2334e-02, -1.5606e-03,  3.5716e-02,  1.5041e-02,  2.8508e-02,\n",
      "        -2.1102e-02,  2.7418e-02, -4.7936e-03,  1.4250e-02, -5.3427e-03,\n",
      "        -2.2862e-02, -7.1275e-03, -2.0907e-02, -2.4497e-02,  2.0650e-02,\n",
      "         3.7873e-04,  9.9192e-03, -3.1237e-02, -1.4842e-02,  9.9226e-03,\n",
      "         1.6180e-02,  2.6961e-02,  2.4955e-02, -2.3080e-02,  3.8238e-03,\n",
      "        -1.5820e-02, -1.1879e-02, -2.8116e-02,  3.5475e-02, -7.2330e-03,\n",
      "         1.1268e-02, -1.5849e-02, -1.0698e-02,  1.2942e-02,  2.3555e-02,\n",
      "        -1.3173e-02,  5.9920e-03,  4.9659e-03, -4.1062e-03, -5.8380e-03,\n",
      "         2.7109e-02,  1.4579e-02, -3.4472e-03, -2.7413e-02, -2.5414e-02,\n",
      "         1.5197e-02,  1.9593e-02, -9.4397e-03,  4.0594e-03,  2.2421e-02,\n",
      "         3.1679e-03, -6.9210e-03,  1.3396e-02, -1.8269e-02, -1.4501e-02,\n",
      "        -2.4149e-02,  1.6769e-02,  1.9627e-03, -6.0172e-02,  2.4305e-02,\n",
      "         7.6637e-04, -3.1610e-02,  8.4354e-03,  2.5374e-02, -2.5356e-02,\n",
      "         3.7110e-03, -1.1090e-02, -1.0911e-02,  5.7249e-03, -9.5240e-03,\n",
      "        -2.6692e-02, -1.4196e-02, -3.5487e-05,  1.7387e-02, -1.1337e-04,\n",
      "         1.1761e-02,  2.0325e-02, -1.9845e-02, -2.6025e-03,  5.1328e-03,\n",
      "         4.2468e-02,  2.0778e-02, -1.5325e-02, -2.9519e-02,  6.8549e-03,\n",
      "        -3.3422e-02,  8.8341e-03,  9.5522e-03, -2.7068e-02, -9.1256e-03,\n",
      "         4.3956e-02,  3.5903e-02, -9.7140e-03,  5.3677e-03, -3.1694e-02,\n",
      "        -1.3052e-02, -3.2210e-02,  2.1790e-03, -1.0252e-02,  2.1892e-02,\n",
      "        -8.4774e-03,  1.3271e-02, -4.6412e-02,  2.8615e-04,  6.7860e-03,\n",
      "         1.1548e-02, -3.6257e-02,  6.6947e-03,  1.3295e-02,  9.3339e-03,\n",
      "        -1.3190e-02,  1.7917e-02, -1.0038e-02, -1.2037e-02, -4.4468e-02,\n",
      "         1.3449e-02,  4.8194e-03,  2.0942e-03, -5.6042e-04, -3.9901e-02,\n",
      "        -1.6221e-02,  2.1504e-02, -5.9496e-03,  1.7315e-02, -2.3739e-02,\n",
      "         1.1921e-02, -4.6485e-03, -1.1992e-02,  5.0069e-02, -1.8647e-02,\n",
      "         3.0489e-02,  3.4839e-03,  3.0958e-03, -6.4919e-04, -1.4938e-02,\n",
      "        -2.2639e-02,  7.7748e-03, -9.0520e-03, -3.1982e-02, -2.1683e-02,\n",
      "        -2.3368e-02, -8.5646e-03, -2.7960e-02, -3.4495e-02, -2.1010e-02,\n",
      "        -1.1179e-02,  4.0364e-02, -3.7422e-02,  5.7377e-03, -2.3829e-02,\n",
      "         3.5565e-03,  1.5575e-02, -1.5859e-02, -2.9574e-04, -1.0521e-02,\n",
      "        -1.6457e-02,  9.2162e-03, -3.8563e-02,  2.7748e-02, -1.7630e-02,\n",
      "        -2.1362e-02,  5.1301e-03, -3.1660e-02, -3.1935e-02, -1.5942e-03,\n",
      "        -1.3199e-02, -2.7087e-02,  2.1427e-02,  8.9130e-03,  2.3905e-02,\n",
      "         9.0569e-03, -4.8617e-03,  3.7978e-02,  2.7949e-02, -7.4296e-03,\n",
      "        -3.7734e-02, -2.5842e-02,  1.7961e-02, -2.6131e-02,  3.5111e-02,\n",
      "         1.5354e-02,  8.6263e-03,  4.9374e-02,  5.4746e-03, -1.8753e-02,\n",
      "         3.8089e-03, -2.8068e-02,  5.7241e-02,  3.6554e-04, -1.6941e-02,\n",
      "         1.2515e-02,  6.6646e-03, -1.8923e-02,  3.0722e-02, -2.1753e-02,\n",
      "        -7.4338e-03, -5.5143e-02, -1.9125e-02, -1.4979e-02, -1.9721e-02,\n",
      "        -2.0692e-02, -1.2146e-02,  1.5385e-02, -8.7342e-04, -1.0958e-02,\n",
      "        -8.0610e-03,  1.0136e-02,  9.7783e-03,  1.4807e-02,  8.6629e-03,\n",
      "        -3.4940e-02, -3.4162e-02,  3.9828e-02, -2.2809e-02,  2.4930e-02,\n",
      "         2.9788e-02, -3.0842e-02,  2.4513e-02, -5.3483e-03,  3.0191e-03,\n",
      "         3.9254e-04, -1.4699e-02, -6.3873e-03, -1.6458e-02,  2.7125e-03,\n",
      "         5.8787e-03, -4.7999e-03,  4.8561e-03,  7.3701e-03, -3.1422e-02,\n",
      "         2.2919e-02,  3.9496e-02, -1.7281e-02,  8.5135e-04,  1.6699e-02,\n",
      "        -1.8669e-02,  2.8443e-02, -1.8285e-02,  4.0068e-03,  8.0415e-03,\n",
      "        -7.8776e-03,  2.3427e-02, -2.0900e-02,  3.4986e-02,  1.5247e-02,\n",
      "         1.2580e-02, -1.3044e-02,  2.7051e-02, -1.6386e-02, -3.7751e-02,\n",
      "        -1.8459e-02,  1.3700e-02,  1.7498e-02,  1.7558e-02,  5.3167e-03,\n",
      "         1.5363e-02, -5.1693e-03, -1.8346e-02, -2.3666e-02,  1.1571e-02,\n",
      "        -1.9110e-02, -1.9714e-02, -2.1613e-02, -1.9715e-03,  9.6715e-03,\n",
      "        -2.3953e-02,  3.4890e-02,  1.4092e-03, -3.8924e-02, -7.4497e-03,\n",
      "         9.1627e-03, -7.3334e-03, -1.5032e-02,  2.4045e-02,  1.4386e-02],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([900])\n",
      "torch.Size([3, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# testing that the autoencoder works.\n",
    "\n",
    "dummy_vector = textToVectors(\"The quick brown fox jumped. Over the lazy, brown Dog!\", word2vec_model)\n",
    "\n",
    "print(dummy_vector.shape)\n",
    "\n",
    "autoencoder = Autoencoder(dummy_vector.shape, 900)\n",
    "decoded, encoded = autoencoder(torch.tensor(dummy_vector).float())\n",
    "\n",
    "print(decoded)\n",
    "print(decoded.shape)\n",
    "\n",
    "print(encoded)\n",
    "print(encoded.shape)\n",
    "\n",
    "reshaped_encoded = encoded.view(3, 300)\n",
    "print(reshaped_encoded.shape)\n",
    "\n",
    "# pass the reshaped_encoded to a vector to word to see what words get produced in the compression layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorsToText(embeddings, word2vec_model):\n",
    "    \"\"\"\n",
    "    Converts a list of embeddings back into words using the Word2Vec model.\n",
    "    \n",
    "    Args:\n",
    "    - embeddings (list of numpy arrays): List of vector embeddings.\n",
    "    - word2vec_model (Word2Vec): Gensim Word2Vec model.\n",
    "    \n",
    "    Returns:\n",
    "    - words (list of str): List of words corresponding to the embeddings.\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for vector in embeddings:\n",
    "        vector_np = vector.detach().numpy()\n",
    "        # Normalize the vector to have unit length\n",
    "        normalized_vector = vector_np / np.linalg.norm(vector_np)\n",
    "        try:\n",
    "            # Find the most similar word to the given normalized vector\n",
    "            similar_word = word2vec_model.most_similar(positive=[normalized_vector], topn=1)[0][0]\n",
    "            words.append(similar_word)\n",
    "        except KeyError:\n",
    "            # If the normalized vector doesn't correspond to any word, append a placeholder\n",
    "            words.append(\"UNKNOWN_WORD\")\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meiya', 'Leezza', 'Shiias']\n"
     ]
    }
   ],
   "source": [
    "words = vectorsToText(reshaped_encoded, word2vec_model)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 15.6k/15.6k [00:00<00:00, 13.8MB/s]\n",
      "Downloading data: 100%|██████████| 257M/257M [00:11<00:00, 22.6MB/s] \n",
      "Downloading data: 100%|██████████| 257M/257M [00:12<00:00, 20.6MB/s] \n",
      "Downloading data: 100%|██████████| 259M/259M [00:13<00:00, 19.8MB/s] \n",
      "Downloading data: 100%|██████████| 34.7M/34.7M [00:01<00:00, 20.1MB/s]\n",
      "Downloading data: 100%|██████████| 30.0M/30.0M [00:01<00:00, 18.3MB/s]\n",
      "Generating train split: 100%|██████████| 287113/287113 [00:01<00:00, 273195.07 examples/s]\n",
      "Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 260027.44 examples/s]\n",
      "Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 260773.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"cnn_dailymail\", '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataLoader: 287113\n",
      "Length of Custom Dataset: 287113\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.articles = dataset['train']['article']\n",
    "        self.summaries = dataset['train']['highlights']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract the article and summary from the dataset\n",
    "        article = self.articles[idx]\n",
    "        summary = self.summaries[idx]\n",
    "        return article, summary\n",
    "\n",
    "# Instantiate your custom dataset using only the training set\n",
    "custom_dataset = MyDataset(dataset)\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Length of DataLoader:\", len(dataloader))\n",
    "print(\"Length of Custom Dataset:\", len(custom_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressVectorsPCA(data, target_count):\n",
    "    pca = PCA(n_components=target_count)\n",
    "    compressed_data = pca.fit_transform(data.T).T\n",
    "    return compressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_training(model, loss_function, optimizer, train_data, n_epochs, update_interval):\n",
    "    \"\"\"\n",
    "    Function for training an autoencoder model.\n",
    "\n",
    "    Args:\n",
    "    - model (nn.Module): Autoencoder model.\n",
    "    - loss_function: Loss function.\n",
    "    - optimizer: Optimizer.\n",
    "    - train_data (DataLoader): DataLoader for the training data.\n",
    "    - n_epochs (int): Number of epochs for training.\n",
    "    - update_interval (int): Interval for logging and updating losses.\n",
    "\n",
    "    Returns:\n",
    "    - model (nn.Module): Trained autoencoder model.\n",
    "    - losses (list): List of losses during training.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for articles, summaries in train_data:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Convert articles to embeddings\n",
    "            article_embedding = textToVectors(articles[0], word2vec_model)\n",
    "\n",
    "            compressed_vector = compressVectorsPCA(article_embedding, 13)\n",
    "\n",
    "            decoded, encoded = model(torch.tensor(compressed_vector).float())\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_function(decoded, torch.tensor(compressed_vector).float())\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Logging and updating losses\n",
    "            if batch_count % update_interval == 0:\n",
    "                losses.append(epoch_loss / batch_count)\n",
    "\n",
    "        epoch_loss /= len(train_data)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Subset DataLoader: 100\n"
     ]
    }
   ],
   "source": [
    "subset_sampler = SubsetRandomSampler(range(100))\n",
    "\n",
    "# Create a PyTorch DataLoader for the subset\n",
    "subset_dataloader = DataLoader(custom_dataset, batch_size=batch_size, sampler=subset_sampler)\n",
    "\n",
    "print(\"Length of Subset DataLoader:\", len(subset_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder((13,300), 900)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Train the autoencoder\n",
    "n_epochs = 1\n",
    "update_interval = 100\n",
    "trained_autoencoder, losses = autoencoder_training(autoencoder, loss_function, optimizer, subset_dataloader, n_epochs, update_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/2271388024.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_vector = vector_np / np.linalg.norm(vector_np)\n",
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', '----------_-----------------------------------------------_GS##', 'dog', 'lazy', 'fox', 'quick', 'ERNEST_DOROSZUK_QMI_AGENCY', 'over', 'Mark_Kornblau_spokesman', 'mythological', 'parapsychologist', 'unleashing_torrents', '</s>']\n",
      "tensor([[ 0.0326,  0.0605,  0.0561,  ..., -0.0821,  0.0632,  0.0150],\n",
      "        [-0.0026, -0.0166,  0.0062,  ...,  0.0215,  0.0145,  0.0138],\n",
      "        [-0.0053,  0.0044, -0.0231,  ...,  0.0009, -0.0107,  0.0188],\n",
      "        ...,\n",
      "        [ 0.0173,  0.0100, -0.0143,  ...,  0.0020,  0.0114,  0.0013],\n",
      "        [ 0.0068,  0.0026,  0.0118,  ...,  0.0084, -0.0032,  0.0110],\n",
      "        [-0.0324, -0.0039, -0.0061,  ...,  0.0069, -0.0196,  0.0074]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([13, 300])\n",
      "tensor([-6.7036e-02, -1.5886e-01, -4.2261e-02, -6.0529e-02, -1.5233e-01,\n",
      "        -7.3305e-02, -8.8234e-02, -1.1837e-01, -1.3985e-01, -7.4195e-02,\n",
      "        -1.9743e-02, -8.4526e-02, -1.1526e-01, -7.7245e-02,  4.2092e-02,\n",
      "        -1.1828e-01, -5.8712e-02, -1.0940e-01, -1.3519e-01, -1.0245e-01,\n",
      "        -8.3431e-02, -6.1519e-02, -3.2520e-02, -4.5470e-02, -7.9504e-02,\n",
      "        -8.8962e-02, -5.7140e-02, -1.1545e-01, -1.4756e-01, -6.0057e-02,\n",
      "        -1.5658e-03, -1.1843e-02, -1.6968e-01, -1.6170e-01,  4.7202e-02,\n",
      "        -8.3381e-02, -6.2755e-02,  1.3759e-02, -1.2996e-01, -7.2807e-02,\n",
      "        -8.8524e-02, -5.9454e-02, -1.8014e-01, -1.5388e-01, -4.6075e-02,\n",
      "        -1.3912e-01, -4.6715e-02, -2.0495e-01, -1.5646e-01, -5.8417e-02,\n",
      "        -9.3618e-02, -9.8820e-02, -9.4060e-02, -1.3481e-01, -1.6663e-02,\n",
      "        -3.5100e-02, -4.6433e-02, -1.7192e-01, -1.0814e-01,  1.2613e-01,\n",
      "        -2.4892e-01,  6.3228e-02, -8.5635e-02, -1.6364e-01, -1.9475e-01,\n",
      "        -8.7464e-02, -2.0873e-01, -7.1944e-02, -1.2910e-01, -1.4806e-01,\n",
      "        -1.0081e-01,  1.0348e-01, -6.5996e-02, -1.1695e-01,  8.9361e-02,\n",
      "        -1.1580e-01, -9.4106e-02, -1.1505e-01, -6.3408e-02, -2.8706e-02,\n",
      "         4.0211e-02, -1.2688e-01, -4.6915e-02, -9.7327e-02, -3.4673e-02,\n",
      "        -6.1082e-02, -7.6084e-02, -4.4680e-02, -5.8955e-02, -8.4053e-02,\n",
      "         2.0636e-02, -6.2450e-02, -8.3061e-02, -1.2622e-01, -1.4221e-01,\n",
      "         1.3324e-01, -1.2296e-01, -1.6325e-01, -6.3806e-02, -8.6062e-02,\n",
      "        -2.0591e-01, -2.8222e-01,  1.6270e-03,  1.0956e-01, -6.3442e-02,\n",
      "        -1.2848e-01, -9.2898e-02, -8.8973e-02, -8.8273e-02, -1.2536e-01,\n",
      "        -1.5938e-01, -6.4897e-02, -1.7109e-01, -1.1225e-01, -1.6621e-01,\n",
      "        -6.8212e-02, -1.2557e-01,  1.3739e-01, -1.4402e-01, -4.7946e-02,\n",
      "        -1.5022e-01, -1.8968e-01,  8.4117e-02, -1.7576e-01, -2.1187e-02,\n",
      "        -3.4852e-03, -3.5920e-02, -3.3019e-02, -1.0673e-01, -7.9305e-02,\n",
      "        -9.8239e-02, -1.6720e-01, -6.4659e-02, -5.4285e-02, -5.0429e-02,\n",
      "        -9.8964e-02, -3.4923e-02, -1.2975e-01, -7.1144e-02, -1.0615e-01,\n",
      "        -1.1417e-01, -1.7338e-02, -7.8798e-02, -1.5352e-01, -8.6265e-02,\n",
      "        -1.0063e-01, -1.6841e-01, -7.0750e-02, -4.8544e-02, -9.4280e-02,\n",
      "         1.7424e-01, -1.0242e-01, -1.1668e-01, -1.3328e-01,  4.4444e-02,\n",
      "        -1.2200e-01, -1.2730e-01, -1.5264e-01, -7.7019e-02, -8.8027e-02,\n",
      "        -2.2330e-02, -5.1251e-02, -1.2161e-01, -5.0718e-02, -2.4570e-03,\n",
      "        -8.7894e-02, -9.2832e-02, -1.0238e-01, -9.5470e-02, -2.1760e-01,\n",
      "        -1.8837e-01,  2.1060e-01, -7.5105e-02, -1.3752e-02, -1.8379e-01,\n",
      "         9.8195e-02, -6.6865e-02, -6.5292e-02, -1.5306e-02, -7.7113e-02,\n",
      "        -4.3680e-02, -6.7026e-02, -1.3931e-01, -7.1593e-02, -1.0420e-01,\n",
      "        -1.1525e-01, -5.2255e-02, -6.9149e-02, -9.9505e-02, -2.4779e-02,\n",
      "        -8.5658e-02, -1.0771e-01, -1.0089e-01,  2.6637e-02, -1.0679e-01,\n",
      "        -1.4068e-01, -7.8260e-02, -6.6198e-02, -2.5725e-02, -1.4829e-01,\n",
      "        -3.7324e-03, -1.4655e-01, -1.2707e-01,  1.8284e-05, -2.2257e-01,\n",
      "        -8.9753e-02, -8.4049e-02, -1.8839e-01, -6.4868e-02, -2.2475e-02,\n",
      "        -1.3909e-01, -6.8815e-02, -1.3624e-01, -4.0291e-02, -1.6939e-01,\n",
      "         2.7173e-02, -3.0556e-02, -1.3235e-01, -1.0884e-01,  3.5363e-02,\n",
      "        -1.1960e-01, -1.2198e-01, -3.9243e-02, -5.7924e-02, -1.5883e-01,\n",
      "        -1.4082e-01,  1.2830e-02,  1.2842e-01, -3.6670e-02, -7.4493e-02,\n",
      "        -1.6495e-01, -7.6891e-02, -1.5749e-01, -5.0462e-02,  2.0341e-02,\n",
      "         8.5914e-02, -2.1353e-01, -1.1390e-01,  1.3765e-01,  5.0606e-02,\n",
      "        -1.3108e-01, -7.4998e-02, -1.0330e-01, -2.0741e-02, -7.7121e-02,\n",
      "        -4.5792e-02,  8.9624e-02, -9.4849e-02, -3.9412e-02, -1.7323e-01,\n",
      "        -2.1099e-01, -8.2137e-02, -1.3732e-01, -1.0177e-01, -1.4745e-01,\n",
      "         7.3406e-02, -1.1429e-01,  5.0096e-02, -9.4784e-02, -1.4486e-01,\n",
      "        -1.4528e-01, -6.7371e-02, -1.0620e-01, -5.1300e-02,  5.3027e-02,\n",
      "        -9.7678e-02,  9.6896e-03, -3.5092e-02,  2.7103e-02, -1.0860e-01,\n",
      "        -1.8356e-01, -1.7569e-01, -5.0757e-02,  2.7501e-02, -9.5916e-02,\n",
      "         5.8888e-02, -1.2979e-01, -7.4843e-02, -2.6859e-02,  1.5766e-04,\n",
      "        -1.2719e-01,  9.2187e-02, -1.4044e-01, -1.2191e-01,  6.5469e-02,\n",
      "         6.2511e-02, -1.5896e-01, -9.6197e-02, -1.9251e-01, -8.7284e-02,\n",
      "         2.0614e-01, -9.9936e-02, -9.0424e-02, -1.4426e-02, -1.2477e-01,\n",
      "        -9.8591e-02, -1.0195e-01,  5.0022e-02, -9.6449e-02, -3.0941e-02,\n",
      "         5.4112e-02, -4.2937e-02,  6.4977e-02, -8.8313e-02,  1.5613e-01,\n",
      "        -4.7252e-02, -1.0771e-01, -4.8225e-02, -3.0131e-02, -2.6171e-01,\n",
      "        -1.2176e-01,  4.1788e-02, -1.0859e-01, -2.4473e-01, -5.7565e-02,\n",
      "        -2.1012e-02,  2.0440e-01, -9.8948e-02, -3.6986e-02, -8.4745e-02,\n",
      "        -6.9825e-02,  1.0882e-01,  6.8616e-02, -1.8040e-01, -1.0373e-01,\n",
      "        -9.3253e-02, -1.3857e-01, -7.5091e-03, -2.4284e-02, -6.2573e-02,\n",
      "        -8.9966e-02, -3.1185e-02, -3.5690e-02, -3.7588e-02, -5.1141e-02,\n",
      "        -9.1596e-02, -9.9831e-02, -2.4622e-01, -1.7787e-01,  3.7564e-04,\n",
      "        -5.5677e-02, -9.8856e-03, -1.2309e-02, -1.8737e-02, -1.5880e-01,\n",
      "        -1.5425e-01,  3.0518e-03, -1.1849e-01,  9.4791e-02, -2.1681e-02,\n",
      "        -1.2116e-01, -8.1932e-02,  1.9587e-02, -1.5233e-01, -1.0520e-01,\n",
      "        -1.8579e-01, -7.7625e-02, -1.3866e-01, -5.9870e-02, -7.3508e-02,\n",
      "        -6.4750e-02, -6.1888e-02,  4.6067e-02, -1.6223e-01, -5.2202e-02,\n",
      "        -1.4527e-01, -1.2450e-01, -4.7605e-02, -1.0683e-01, -1.1557e-01,\n",
      "        -1.0771e-01, -1.8917e-01, -1.4907e-01, -1.4599e-01, -7.9992e-02,\n",
      "        -1.8951e-02, -7.4604e-02,  9.2500e-03, -5.4776e-02, -8.4019e-02,\n",
      "        -1.0798e-01, -7.7263e-02, -1.5260e-01, -3.8773e-02, -2.1967e-01,\n",
      "        -1.0814e-01,  3.7866e-02, -9.5969e-02,  1.7503e-02, -2.9885e-02,\n",
      "        -1.4389e-01, -8.3708e-02, -9.5292e-02, -7.7944e-02, -3.5729e-02,\n",
      "        -5.4616e-02, -8.3826e-02, -1.1031e-01, -8.0987e-02, -1.7183e-01,\n",
      "        -7.7855e-02, -1.0271e-01, -5.3367e-02, -3.5927e-02, -7.2503e-02,\n",
      "         1.7349e-02, -1.1906e-01, -6.5428e-02, -1.1719e-01, -1.4728e-01,\n",
      "        -2.8961e-02, -1.0345e-01, -1.8030e-01, -7.9773e-02,  8.7344e-02,\n",
      "        -5.9235e-02, -4.2691e-02, -1.4366e-01, -1.0785e-01,  7.8200e-02,\n",
      "        -2.3871e-02, -6.9029e-02, -6.9671e-02, -5.7162e-02, -7.0158e-02,\n",
      "        -1.3876e-01, -7.5074e-02, -1.3129e-01, -1.9793e-01, -1.0634e-01,\n",
      "        -7.8739e-02, -1.3024e-01, -6.7551e-02, -6.4286e-02, -8.5211e-02,\n",
      "        -5.8369e-02, -1.2534e-01,  4.2418e-02, -6.1370e-02, -1.8476e-01,\n",
      "        -1.5519e-01, -1.1392e-01, -7.4315e-02,  1.0869e-01, -1.2050e-01,\n",
      "        -4.5638e-02,  4.3280e-02, -6.2888e-02, -1.0693e-01, -1.4376e-01,\n",
      "         3.7233e-02, -7.7917e-02, -5.7553e-02,  1.5530e-02, -2.1521e-02,\n",
      "        -8.2771e-02, -6.4023e-02, -3.9346e-02, -6.0733e-02, -9.4931e-02,\n",
      "        -3.5493e-02,  2.0506e-01,  3.8223e-02, -5.9803e-02, -9.2890e-02,\n",
      "        -1.4737e-02, -1.0740e-01, -5.8717e-02, -1.3787e-01, -9.5967e-02,\n",
      "        -1.1833e-01, -7.4721e-02, -4.6060e-02, -1.4329e-01, -1.6964e-01,\n",
      "        -1.5047e-01, -1.8936e-01, -5.3224e-02, -7.4505e-02, -6.9921e-03,\n",
      "        -1.2426e-01, -8.4294e-02, -1.3964e-01, -7.3283e-02, -1.5037e-01,\n",
      "        -8.6052e-02, -1.3596e-01, -1.4635e-01, -6.2788e-02,  1.9842e-01,\n",
      "        -8.3376e-02, -1.8147e-02, -1.9368e-01, -2.1072e-02, -1.1937e-01,\n",
      "         2.2349e-02, -6.3412e-02,  2.0936e-02, -8.2773e-02, -1.5325e-01,\n",
      "        -9.9769e-02, -6.1060e-02, -7.2010e-02, -1.5625e-01, -8.2764e-02,\n",
      "        -1.3338e-01, -2.4701e-02,  1.5377e-01, -3.5338e-02, -1.7453e-01,\n",
      "         8.1356e-03, -4.5323e-02, -7.1083e-02, -6.4016e-02,  1.5520e-02,\n",
      "        -1.3547e-01, -1.5270e-01, -4.6965e-02, -1.4987e-01, -1.0144e-01,\n",
      "        -7.4276e-03, -1.2348e-01, -2.0363e-01, -1.8669e-01, -5.5599e-02,\n",
      "        -1.1645e-01, -1.0334e-02, -1.8882e-01, -6.3666e-03,  2.4198e-03,\n",
      "        -8.4136e-02,  1.6156e-01, -9.9699e-02, -4.7968e-02, -1.3845e-01,\n",
      "         6.4457e-02, -1.3101e-01, -8.2181e-02, -6.6946e-02,  2.0168e-02,\n",
      "        -1.6515e-01, -1.2325e-01, -9.2637e-02, -5.7772e-02, -1.6738e-01,\n",
      "        -9.3129e-02, -8.7326e-02, -7.2803e-02,  6.3448e-02, -1.9125e-01,\n",
      "         1.7590e-02, -1.2673e-01, -6.0933e-02, -1.4295e-01, -1.5221e-01,\n",
      "        -4.8112e-02, -3.0351e-02, -1.7518e-01, -8.2394e-02,  1.7306e-01,\n",
      "         1.8546e-01, -8.5105e-02, -1.0698e-01, -2.5109e-02, -1.3395e-01,\n",
      "         9.2767e-02, -1.0526e-01, -6.1105e-02, -1.6385e-01, -1.0378e-01,\n",
      "        -3.0395e-02, -1.3946e-01, -7.1676e-02, -2.0649e-02, -8.4185e-02,\n",
      "        -1.1042e-01, -8.1254e-02, -1.5262e-01, -6.3688e-02, -4.6673e-02,\n",
      "        -1.0842e-01, -1.5434e-01, -6.2598e-02, -1.1933e-01,  8.9871e-02,\n",
      "        -1.6014e-01, -1.4690e-01, -1.8567e-02,  1.7402e-03,  4.9848e-02,\n",
      "        -1.4068e-02, -9.6159e-02, -4.7814e-02, -9.4448e-02, -5.0009e-04,\n",
      "        -2.3993e-02, -1.0670e-01, -1.0909e-01, -9.3911e-02,  4.5244e-02,\n",
      "        -5.2024e-02, -8.6658e-02, -6.7170e-02, -1.6238e-01,  1.4908e-02,\n",
      "        -1.5084e-02, -6.3921e-02, -1.3606e-01, -3.2696e-02, -7.1406e-02,\n",
      "        -2.1155e-01, -9.5923e-02, -1.4477e-01, -7.3341e-02, -1.4397e-01,\n",
      "        -1.3495e-01, -6.6384e-02,  1.2828e-03, -1.9259e-01,  1.0260e-01,\n",
      "        -8.9466e-02, -1.8825e-01, -1.2497e-01, -1.2002e-01, -6.0453e-02,\n",
      "        -9.4364e-02, -1.0946e-01, -1.1553e-01, -4.1861e-02, -8.1563e-02,\n",
      "        -3.9889e-02, -9.8773e-02, -5.1948e-02, -9.4879e-02,  1.5146e-03,\n",
      "        -1.2967e-01, -1.4524e-01, -1.5208e-02, -2.2305e-02, -2.3489e-01,\n",
      "        -2.8884e-02,  1.1192e-01,  2.3889e-02, -5.3579e-02, -2.3318e-02,\n",
      "        -6.4908e-02, -2.4671e-01, -1.3691e-01, -6.8093e-02, -1.7347e-01,\n",
      "        -5.1611e-02, -1.2300e-01, -1.2421e-01,  7.5337e-04, -4.3286e-02,\n",
      "        -7.2170e-02, -1.3992e-01, -1.4605e-01, -1.3589e-01, -5.0667e-02,\n",
      "        -2.1388e-02, -3.9585e-02, -1.3175e-01, -1.0027e-01, -1.2779e-01,\n",
      "        -2.0092e-01, -1.1573e-01, -6.0286e-02, -4.8448e-02, -1.2660e-01,\n",
      "        -1.9042e-01,  1.6436e-01,  8.5773e-02, -7.8878e-02, -6.6995e-02,\n",
      "        -2.2237e-01, -1.9351e-01, -7.2213e-02,  4.3107e-02, -1.5876e-01,\n",
      "        -7.7263e-02,  1.3422e-01, -3.6661e-02, -5.6690e-02, -9.8759e-02,\n",
      "        -1.0881e-01, -1.8277e-02, -3.2872e-02,  1.1158e-01, -1.1529e-01,\n",
      "        -2.5293e-02, -1.0340e-01, -8.5330e-02, -2.2154e-01, -8.8372e-02,\n",
      "        -1.0418e-01, -3.4779e-02, -8.7997e-02, -8.8106e-02,  1.0459e-01,\n",
      "        -7.6442e-02, -7.5987e-03, -5.7298e-02, -4.9576e-02, -8.3933e-02,\n",
      "        -1.2835e-02, -1.1265e-01,  5.2314e-03, -1.5631e-01, -5.1055e-02,\n",
      "        -1.0369e-01, -1.0109e-01, -1.1628e-01, -9.8507e-02, -1.1208e-01,\n",
      "        -7.6629e-02, -2.7213e-02, -1.3183e-01, -1.2527e-01, -6.5140e-03,\n",
      "        -1.3417e-01,  8.7574e-02,  6.7860e-02,  8.3916e-02, -5.6912e-02,\n",
      "        -6.6288e-02, -1.9660e-01, -9.7053e-02, -1.5495e-01, -3.3090e-02,\n",
      "        -5.9981e-02,  4.1521e-02, -3.3530e-02, -1.4339e-01, -8.4423e-02,\n",
      "        -1.0650e-01,  2.1158e-02, -1.3126e-01,  1.2606e-02, -1.5622e-01,\n",
      "        -1.2956e-01, -1.4496e-02,  1.9997e-02, -1.0034e-02,  1.0732e-02,\n",
      "        -9.6479e-02, -1.0383e-02, -1.6744e-01,  1.4804e-01, -1.2469e-01,\n",
      "         1.5153e-02, -6.1974e-02, -8.5372e-02, -1.8575e-02, -2.8253e-02,\n",
      "        -1.7760e-01, -1.1195e-01, -9.7237e-02, -1.2313e-01, -1.1053e-01,\n",
      "        -6.6463e-02, -1.1205e-01, -1.3233e-01, -2.3780e-02,  7.7165e-02,\n",
      "        -5.5030e-03, -8.8015e-02, -3.5538e-02, -2.1138e-01, -7.8115e-02,\n",
      "        -1.1558e-01,  5.2046e-03,  5.0754e-02, -1.1082e-01, -2.9921e-02,\n",
      "        -4.4627e-02, -1.8967e-01, -3.6783e-02, -6.2855e-02, -4.7546e-02,\n",
      "        -8.9041e-02, -8.4744e-02, -5.1153e-02, -3.6840e-02, -1.5220e-01,\n",
      "        -4.2810e-02, -1.0445e-01, -1.0376e-01, -5.4963e-02, -4.2903e-02,\n",
      "        -3.7267e-02, -1.0864e-01, -9.3040e-02, -1.1463e-01,  6.0057e-02,\n",
      "        -9.3852e-02, -3.3490e-02, -1.1648e-01, -2.1430e-01, -7.2999e-02,\n",
      "        -1.2906e-01, -8.2531e-02, -1.3590e-01, -1.2554e-01, -7.9916e-02,\n",
      "        -9.1982e-02,  5.5348e-02, -1.4688e-01,  6.8977e-02, -1.4130e-01,\n",
      "        -2.7109e-02, -6.2817e-02, -7.5416e-02, -3.9310e-02, -1.4820e-02,\n",
      "        -4.9206e-02, -1.3145e-01, -9.7012e-02,  4.2869e-02, -1.0485e-01,\n",
      "        -1.0257e-01, -4.6610e-02, -1.4762e-01, -7.7741e-02, -3.2806e-02,\n",
      "        -1.3199e-01, -1.4583e-01, -3.5142e-02,  5.8559e-02, -8.7184e-03,\n",
      "        -9.4307e-02, -3.3645e-03, -8.5610e-02, -4.0231e-02,  1.3149e-02,\n",
      "         1.1066e-01, -2.9920e-02, -3.7871e-02, -1.0748e-01, -5.0175e-02,\n",
      "        -1.3971e-01, -2.6879e-02, -9.7206e-02, -3.6331e-02, -1.6492e-01,\n",
      "        -1.8113e-01, -1.0049e-01, -1.6497e-02, -4.8536e-02, -7.6710e-02,\n",
      "        -7.6837e-02, -2.5536e-02, -4.5644e-02, -1.5347e-01, -1.4403e-01,\n",
      "        -8.9415e-02, -9.9873e-02, -1.3546e-01, -9.4689e-02, -6.6359e-02,\n",
      "        -4.4371e-02, -1.8364e-01,  9.5703e-02, -7.3908e-02, -9.0671e-02,\n",
      "        -7.6214e-02, -3.8327e-02, -5.3991e-03, -8.5545e-03, -3.5294e-02,\n",
      "        -1.3805e-01, -4.8454e-02, -6.6114e-02,  2.3749e-02, -1.5153e-01,\n",
      "        -1.0117e-01, -7.1501e-02, -1.4600e-01, -1.6894e-01, -1.5024e-01,\n",
      "        -1.3914e-01, -3.8681e-02, -8.9368e-02, -1.3465e-01, -1.1748e-02,\n",
      "        -4.1960e-02,  2.1221e-02, -1.8775e-01, -1.1776e-01, -1.0375e-01,\n",
      "         2.4476e-02,  1.2816e-01, -7.3041e-02, -1.4675e-02,  5.9350e-02,\n",
      "        -7.7774e-02, -5.6087e-02, -5.9911e-02, -1.4892e-01, -2.1844e-02],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([900])\n",
      "torch.Size([3, 300])\n",
      "['MapInfo_Exponare', 'pollinated', 'andsupport']\n"
     ]
    }
   ],
   "source": [
    "dummy_vector = textToVectors(\"The quick brown fox jumped. Over the lazy, brown Dog!\", word2vec_model)\n",
    "\n",
    "compressed_vector = compressVectorsPCA(dummy_vector, 13)\n",
    "\n",
    "print(compressed_vector.shape)\n",
    "\n",
    "print(vectorsToText(torch.tensor(compressed_vector), word2vec_model))\n",
    "\n",
    "decoded, encoded = trained_autoencoder(torch.tensor(dummy_vector).float())\n",
    "\n",
    "print(decoded)\n",
    "print(decoded.shape)\n",
    "\n",
    "print(encoded)\n",
    "print(encoded.shape)\n",
    "\n",
    "reshaped_encoded = encoded.view(3, 300)\n",
    "print(reshaped_encoded.shape)\n",
    "\n",
    "words = vectorsToText(reshaped_encoded, word2vec_model)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/g654jn8x2pb_10qhh6pnnbzr0000gn/T/ipykernel_21265/3185637845.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features_flat = torch.tensor(features_flat, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900])\n",
      "torch.Size([1500])\n",
      "torch.Size([2400])\n",
      "['Korangi', 'BSF_Jawans', 'st_Airborne_Division', 'Korangi', 'Korangi']\n",
      "['Laflèche', 'wallet_sized_passcards', 'judge_Caroline_Goulborn', 'Joe_Pytka', 'ChopHouse', 'nonhierarchical', 'greywacke', 'Taylor_Housewright']\n",
      "torch.Size([13, 300])\n",
      "['K.Kahne_###-###', 'Kerrick_Alumbaugh_pleaded', 'Aftel', 'gnc.com_bodybuilding.com_amazon.com', ',4', 'SHIPPINGPORT_Pa.', 'told', 'Cianci_Corrente', 'Maanzo', 'eating_Veggie_Booty', 'Unique_Motorcars', 'thismonth', 'By_ANNIE_YOUDERIAN']\n",
      "torch.Size([13, 300])\n",
      "['henry', 'M.Martin_###-###', 'julia', 'los_Estados_Unidos', 'inks_pact', 'Corp._nasdaq_SYMC', 'Miss_Subasi', 'constitutional_infirmity', 'want', 'Acute_Respiratory_Infections', 'Balou', 'suffering_brain_aneurysm', 'been']\n",
      "torch.Size([13, 300])\n",
      "['bolton', 'See_Minn._Stat', 'mart.com', 'supporting_TI_DSPs', 'progra_mme', 'Etsuko_Nomura_mother', 'lingering_animosity', 'BRONWYN_BISHOP', 'Hamdi_Shaqqura', 'Salmonellosis', 'underlay', 'generous_philanthropists', 'THE_WATCHMAN']\n"
     ]
    }
   ],
   "source": [
    "# testing skip connections\n",
    "\n",
    "encoder = trained_autoencoder.encoder\n",
    "decoder = trained_autoencoder.decoder\n",
    "\n",
    "encoded, out2, out1 = encoder(torch.tensor(dummy_vector).float())\n",
    "\n",
    "print(encoded.shape)\n",
    "print(out2.shape)\n",
    "print(out1.shape)\n",
    "\n",
    "print(vectorsToText(out2.view(5, 300), word2vec_model))\n",
    "print(vectorsToText(out1.view(8, 300), word2vec_model))\n",
    "\n",
    "# passing skipped values to the encoder and seeing if the output is the same as the original encoded value.\n",
    "\n",
    "result1 = decoder(encoded, 0, 0)\n",
    "print(result1.shape)\n",
    "print(vectorsToText(result1, word2vec_model))\n",
    "\n",
    "zer1 = torch.zeros_like(encoded)\n",
    "zer2 = torch.zeros_like(out2)\n",
    "zer3 = torch.zeros_like(out1)\n",
    "\n",
    "result2 = decoder(zer1, out2, zer3)\n",
    "print(result2.shape)\n",
    "print(vectorsToText(result2, word2vec_model))\n",
    "\n",
    "result3 = decoder(zer1, zer2, out1)\n",
    "print(result3.shape)\n",
    "print(vectorsToText(result3, word2vec_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to Consider:\n",
    "\n",
    "-) Pre-processing the dataset so that we have converted the texts into a numpy array of M words times N dimensions based on which word2vector training model we are trying to use - utilize word_embedding.ipynb .\n",
    "\n",
    "-) Once we have our trained model, we can pass the encodings of different layers into the appropriate decoding layers and plot how the loss compares relative to the complete process.\n",
    "\n",
    "-) Finally , once we have trained our model, defining a function that takes our reshaped output words * dimensions vector embedding and converts it into the most similar words using word2vector pre-defined methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
