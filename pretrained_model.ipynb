{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-OPEN_AI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-text pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image features a serene landscape with a wooden boardwalk extending through a lush meadow. The meadow is filled with tall, green grass and dotted with occasional shrubs and trees. The sky is clear with fluffy clouds and provides a pleasant, vibrant backdrop to the verdant setting. This type of walkway is often used in natural reserves or parks to protect the natural habitat while allowing people to enjoy close contact with nature without damaging it. The scene captures the essence of tranquility and greenery, typical of a well-preserved natural environment.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code uses the OpenAI client object to make a chat completion request using the GPT-4 Turbo model.\n",
    "It sends a user message asking \"What’s in this image?\" along with an image URL. The response from the\n",
    "model is stored in the response variable. The code then prints the assistant's response, which can be \n",
    "accessed using response.choices[0].\n",
    "''' \n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])\n",
    "description = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a predefined set of attributes to extract from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"Color Palette\": \"vibrant greens, clear blue\",\\n    \"Subject Matter\": \"serene landscape\",\\n    \"Mood/Emotion\": \"tranquility\",\\n    \"Style/Aesthetic\": \"naturalistic\",\\n    \"Setting/Location\": \"meadow, boardwalk\",\\n    \"Time Period\": \"contemporary\",\\n    \"Cultural/Symbolic Representation\": \"environmental conservation\"\\n}', role='assistant', function_call=None, tool_calls=None))\n",
      "{\n",
      "    \"Color Palette\": \"vibrant greens, clear blue\",\n",
      "    \"Subject Matter\": \"serene landscape\",\n",
      "    \"Mood/Emotion\": \"tranquility\",\n",
      "    \"Style/Aesthetic\": \"naturalistic\",\n",
      "    \"Setting/Location\": \"meadow, boardwalk\",\n",
      "    \"Time Period\": \"contemporary\",\n",
      "    \"Cultural/Symbolic Representation\": \"environmental conservation\"\n",
      "}\n",
      "{'Color Palette': 'vibrant greens, clear blue', 'Subject Matter': 'serene landscape', 'Mood/Emotion': 'tranquility', 'Style/Aesthetic': 'naturalistic', 'Setting/Location': 'meadow, boardwalk', 'Time Period': 'contemporary', 'Cultural/Symbolic Representation': 'environmental conservation'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "This code uses the OpenAI client object to make a chat completion request using the GPT-4 Turbo model.\n",
    "It prompts the GPT to extract 7 pre-defined attributes from the description of the image input into \n",
    "the image-to-text response above. Then it converts the formatted string object into an object of attributes\n",
    "that we can utilize further using json.\n",
    "''' \n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \n",
    "         # prompt to extract 7 key pre-defined attributes: color palette, subject matter, mood/emotion, style/aesthetic, setting/location, time period, cultural/symbolic representation\n",
    "        \"text\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify the following seven attributes from the given text and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Identify the dominant colors or color schemes present in the image. 2. Subject Matter: Identify the main subject, object, or theme depicted in the image. 3. Mood/Emotion: Identify the overall mood, emotion, or feeling conveyed by the image. 4. Style/Aesthetic: Identify the artistic style, aesthetic, or visual characteristics of the image. 5. Setting/Location: Identify the physical setting, location, or environment depicted in the image. 6. Time Period: Identify the time period, era, or historical context represented in the image. 7. Cultural/Symbolic Representation: Identify any cultural, symbolic, or metaphorical representations present in the image. Please provide your output in the following format: {'Color Palette': 'one or two word adjectives', 'Subject Matter': 'one or two word adjectives', 'Mood/Emotion': 'one or two word adjectives', 'Style/Aesthetic': 'one or two word adjectives', 'Setting/Location': 'one or two word adjectives', 'Time Period': 'one or two word adjectives', 'Cultural/Symbolic Representation': 'one or two word adjectives'}, format the output in double quotations so I can convert it into an object with json.\"\n",
    "},\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\" : description\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=500,\n",
    ")\n",
    "\n",
    "# string reponse from prompt\n",
    "attributes_content = response.choices[0].message.content\n",
    "print(attributes_content)\n",
    "\n",
    "# object to work with data\n",
    "attributes_dict = json.loads(attributes_content)\n",
    "print(attributes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
