{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-OPEN_AI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-text pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m   description \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     39\u001b[0m   descriptions[url] \u001b[38;5;241m=\u001b[39m description\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescriptions:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdumps(descriptions, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code uses the OpenAI client object to make a chat completion request using the GPT-4 Turbo model.\n",
    "It sends a user message asking \"What’s in this image?\" along with an image URL. The response from the\n",
    "model is stored in the response variable. The code then prints the assistant's response, which can be \n",
    "accessed using response.choices[0].\n",
    "''' \n",
    "image_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/08/25/18/48/watercolor-2681039_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2017/03/12/13/41/colorful-2137080_1280.jpg\",\n",
    "    \"https://cdn.pixabay.com/photo/2018/03/30/15/11/deer-3275594_1280.jpg\"\n",
    "    # Add more image URLs as needed\n",
    "]\n",
    "\n",
    "descriptions = {}\n",
    "\n",
    "for url in image_urls:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": url,\n",
    "            },\n",
    "          },\n",
    "        ],\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "  )\n",
    "\n",
    "  # print(response.choices[0])\n",
    "  description = response.choices[0].message.content\n",
    "  descriptions[url] = description\n",
    "\n",
    "print('descriptions:', json.dumps(descriptions, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a predefined set of attributes to extract from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image - Attributes Dictionary:\n",
      " {\n",
      "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\": {\n",
      "        \"Color Palette\": \"vibrant green, vivid blue\",\n",
      "        \"Subject Matter\": \"natural landscape\",\n",
      "        \"Mood/Emotion\": \"peace, tranquility\",\n",
      "        \"Style/Aesthetic\": \"picturesque\",\n",
      "        \"Setting/Location\": \"nature reserve\",\n",
      "        \"Time Period\": \"contemporary\",\n",
      "        \"Cultural/Symbolic Representation\": \"environmental appreciation\"\n",
      "    },\n",
      "    \"https://cdn.pixabay.com/photo/2017/08/25/18/48/watercolor-2681039_1280.jpg\": {\n",
      "        \"Color Palette\": \"vibrant, colorful\",\n",
      "        \"Subject Matter\": \"abstract art\",\n",
      "        \"Mood/Emotion\": \"dynamic, fluid\",\n",
      "        \"Style/Aesthetic\": \"alcohol ink\",\n",
      "        \"Setting/Location\": \"imaginary\",\n",
      "        \"Time Period\": \"contemporary\",\n",
      "        \"Cultural/Symbolic Representation\": \"organic\"\n",
      "    },\n",
      "    \"https://cdn.pixabay.com/photo/2017/03/12/13/41/colorful-2137080_1280.jpg\": {\n",
      "        \"Color Palette\": \"vibrant, colorful\",\n",
      "        \"Subject Matter\": \"colored pencils\",\n",
      "        \"Mood/Emotion\": \"vivid, artistic\",\n",
      "        \"Style/Aesthetic\": \"artistic, contrasting\",\n",
      "        \"Setting/Location\": \"underwater\",\n",
      "        \"Time Period\": \"contemporary\",\n",
      "        \"Cultural/Symbolic Representation\": \"creativity, playfulness\"\n",
      "    },\n",
      "    \"https://cdn.pixabay.com/photo/2018/03/30/15/11/deer-3275594_1280.jpg\": {\n",
      "        \"Color Palette\": \"vibrant, multicolor\",\n",
      "        \"Subject Matter\": \"deer head\",\n",
      "        \"Mood/Emotion\": \"abstract, modern\",\n",
      "        \"Style/Aesthetic\": \"low poly, geometric\",\n",
      "        \"Setting/Location\": \"stylized\",\n",
      "        \"Time Period\": \"contemporary\",\n",
      "        \"Cultural/Symbolic Representation\": \"artistic expression\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "This code uses the OpenAI client object to make a chat completion request using the GPT-4 Turbo model.\n",
    "It prompts the GPT to extract 7 pre-defined attributes from the description of the image input into \n",
    "the image-to-text response above. Then it converts the formatted string object into an object of attributes\n",
    "that we can utilize further using json.\n",
    "''' \n",
    "\n",
    "attributes = {}\n",
    "\n",
    "for url, description in descriptions.items():\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\"type\": \"text\", \n",
    "          # prompt to extract 7 key pre-defined attributes: color palette, subject matter, mood/emotion, style/aesthetic, setting/location, time period, cultural/symbolic representation\n",
    "          \"text\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify the following seven attributes from the given text and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Identify the dominant colors or color schemes present in the image. 2. Subject Matter: Identify the main subject, object, or theme depicted in the image. 3. Mood/Emotion: Identify the overall mood, emotion, or feeling conveyed by the image. 4. Style/Aesthetic: Identify the artistic style, aesthetic, or visual characteristics of the image. 5. Setting/Location: Identify the physical setting, location, or environment depicted in the image. 6. Time Period: Identify the time period, era, or historical context represented in the image. 7. Cultural/Symbolic Representation: Identify any cultural, symbolic, or metaphorical representations present in the image. Please provide your output in the following format: {'Color Palette': 'one or two word adjectives', 'Subject Matter': 'one or two word adjectives', 'Mood/Emotion': 'one or two word adjectives', 'Style/Aesthetic': 'one or two word adjectives', 'Setting/Location': 'one or two word adjectives', 'Time Period': 'one or two word adjectives', 'Cultural/Symbolic Representation': 'one or two word adjectives'}; if an attribute is not obvious, infer from the context of the description an attribute, don't use 'none' or 'not specified' as an attribute. Format the output in double quotations so I can convert it into an object with json. The description is as follows:\" + description,\n",
    "  },\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\" : json.dumps(description)\n",
    "          },\n",
    "        ],\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=500,\n",
    "  )\n",
    "\n",
    "  # string reponse from prompt\n",
    "  attributes_content = response.choices[0].message.content\n",
    "\n",
    "  # object to work with data\n",
    "  attributes_dict = json.loads(attributes_content)\n",
    "\n",
    "  # append to attributes dictionary\n",
    "  attributes[url] = attributes_dict\n",
    "\n",
    "print('Image - Attributes Dictionary:\\n', json.dumps(attributes, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigorous Version of Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image_url):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Please provide a thorough, detailed, and artistic description of the image in the following URL: \" + image_url,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image presents a serene and picturesque scene from a nature boardwalk in Madison, Wisconsin. The focus of the composition is an elegant, curved wooden walkway that invites viewers on a tranquil journey through a lush wetland environment. This gently winding pathway serves not only as a functional element allowing visitors to explore the natural beauty without disturbing the ecosystem but also as a visual guide leading the eye through the varied textures and shades of green of the landscape.\n",
      "\n",
      "The setting is rich with an array of native plants, vivid in various greens that suggest a healthy, vibrant ecosystem. The foliage includes tall grasses which sway slightly, suggesting a gentle breeze. These grasses, interspersed with broader-leaved plants and punctuated occasionally by flowering blooms, create a tapestry of textures and shapes. The diversity of the plant life forms a dense, almost untamed layer that covers the ground and enriches the scene’s depth.\n",
      "\n",
      "Overhead, a sky of mixed clouds — possibly cumulus — softens the light, allowing for a diffuse illumination that enhances colors and reduces harsh shadows. This sky reflects a perfect day for a walk, offering a pleasant climate and ideally soft lighting conditions. The cloud cover also conveys a sense of expansiveness and freedom, adding an airy, open quality to the landscape.\n",
      "\n",
      "The boardwalk itself is crafted of wood with a warm, natural tone that conveys an organic, earthy feel. This choice of material complements the surrounding environment and highlights human intervention designed in harmony with nature. It\n"
     ]
    }
   ],
   "source": [
    "description = image_to_text(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\")\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_to_attributes(description):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify the following seven attributes from the given text and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Identify the dominant colors or color schemes present in the image. 2. Subject Matter: Identify the main subject, object, or theme depicted in the image. 3. Mood/Emotion: Identify the overall mood, emotion, or feeling conveyed by the image. 4. Style/Aesthetic: Identify the artistic style, aesthetic, or visual characteristics of the image. 5. Setting/Location: Identify the physical setting, location, or environment depicted in the image. 6. Time Period: Identify the time period, era, or historical context represented in the image. 7. Cultural/Symbolic Representation: Identify any cultural, symbolic, or metaphorical representations present in the image. Please provide your output in the following format: {'Color Palette': 'one or two word adjectives', 'Subject Matter': 'one or two word adjectives', 'Mood/Emotion': 'one or two word adjectives', 'Style/Aesthetic': 'one or two word adjectives', 'Setting/Location': 'one or two word adjectives', 'Time Period': 'one or two word adjectives', 'Cultural/Symbolic Representation': 'one or two word adjectives'}; if an attribute is not obvious, infer from the context of the description an attribute, don't use 'none' or 'not specified' as an attribute. Format the output in double quotations so I can convert it into an object with json. The description is as follows:\" + description,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    attributes_content = response.choices[0].message.content\n",
    "    attributes_dict = json.loads(attributes_content)\n",
    "\n",
    "    return attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': 'vibrant greens, natural wood', 'Subject Matter': 'nature boardwalk', 'Mood/Emotion': 'serene, tranquil', 'Style/Aesthetic': 'picturesque, naturalistic', 'Setting/Location': 'lush wetland', 'Time Period': 'contemporary', 'Cultural/Symbolic Representation': 'harmony with nature'}\n"
     ]
    }
   ],
   "source": [
    "print(description_to_attributes(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigorous Version of Pre-Defined Model with specific set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_to_attributes_predefined_labels(description):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify and select the most appropriate label from the following pre-defined set of attributes for each of the seven categories given below, and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Select the dominant colors or color schemes present in the image from the following options: [Vibrant, Monochromatic, Pastel, Earthy, Neon, Muted, Bold, Subdued, Contrasting, Harmonious, Warm, Cool, Saturated, Desaturated, Primary, Secondary, Tertiary]. 2. Subject Matter: Choose the main subject, object, or theme depicted in the image from the following options: [Landscape, Portrait, Still life, Abstract, Urban, Nature, Architecture, Human figure, Animals, Plants, Buildings, Interiors, Vehicles, Food, Technology, Fantasy, Surreal, Mythological, Historical event, Everyday objects]. 3. Mood/Emotion: Pick the overall mood, emotion, or feeling conveyed by the image from the following options: [Serene, Energetic, Melancholic, Joyful, Mysterious, Peaceful, Dramatic, Whimsical, Intense, Reflective, Nostalgic, Romantic, Foreboding, Playful, Thoughtful, Soothing, Chaotic, Hopeful]. 4. Style/Aesthetic: Select the artistic style, aesthetic, or visual characteristics of the image from the following options: [Realism, Impressionism, Surrealism, Minimalism, Expressionism, Cubism, Romanticism, Baroque, Renaissance, Gothic, Modernism, Postmodernism, Abstract expressionism, Fauvism, Dadaism, Pop art, Conceptual art]. 5. Setting/Location: Choose the physical setting, location, or environment depicted in the image from the following options: [Cityscape, Countryside, Beach, Forest, Mountains, Urban, Rural, Suburban, Indoor, Outdoor, Coastal, Desert, Arctic, Tropical, Industrial, Historical, Futuristic, Mythical, Extraterrestrial]. 6. Time Period: Pick the time period, era, or historical context represented in the image from the following options: [Contemporary, Renaissance, Medieval, Modern, Ancient, Futuristic, Victorian, Industrial revolution, Middle Ages, Renaissance, Prehistoric, Classical, Baroque, Gothic, Romantic, Edwardian, Roaring twenties, Art Deco, Post-war]. 7. Cultural/Symbolic Representation: Select any cultural, symbolic, or metaphorical representations present in the image from the following options: [Religious, Political, Mythological, Historical, Indigenous, Pop culture, Folklore, Literary, Ethnic, National, International, Gender, Social class, Environmental, Technological, Symbolic, Ritualistic, Iconic, Allegorical, Abstract]. Please provide your output in the following format: {'Color Palette': 'selected option', 'Subject Matter': 'selected option', 'Mood/Emotion': 'selected option', 'Style/Aesthetic': 'selected option', 'Setting/Location': 'selected option', 'Time Period': 'selected option', 'Cultural/Symbolic Representation': 'selected option'}; if an attribute is not obvious, infer from the context of the description an attribute, don't use 'none' or 'not specified' as an attribute. Format the output in double quotations so I can convert it into an object with json. The description is as follows:\" + description\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    attributes_content = response.choices[0].message.content\n",
    "    attributes_dict = json.loads(attributes_content)\n",
    "\n",
    "    return attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': 'Vibrant', 'Subject Matter': 'Nature', 'Mood/Emotion': 'Serene', 'Style/Aesthetic': 'Realism', 'Setting/Location': 'Countryside', 'Time Period': 'Contemporary', 'Cultural/Symbolic Representation': 'Environmental'}\n"
     ]
    }
   ],
   "source": [
    "print(description_to_attributes_predefined_labels(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification of Pre-defined Model with Specific Set of Attributes to provide the 2 best options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_to_attributes_predefined_two(description):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify and select the most appropriate label from the following pre-defined set of attributes for each of the seven categories given below, and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Select up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Vibrant, Monochromatic, Pastel, Earthy, Neon, Muted, Bold]. 2. Subject Matter: Choose up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Landscape, Portrait, Still life, Abstract, Urban, Nature, Architecture]. 3. Mood/Emotion: Pick up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Serene, Energetic, Melancholic, Joyful, Mysterious, Peaceful, Dramatic]. 4. Style/Aesthetic: Select up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Realism, Impressionism, Surrealism, Minimalism, Expressionism, Cubism, Romanticism]. 5. Setting/Location: Choose up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Cityscape, Countryside, Beach, Forest, Mountains, Urban, Rural]. 6. Time Period: Pick up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Contemporary, Renaissance, Medieval, Modern, Ancient, Futuristic, Victorian]. 7. Cultural/Symbolic Representation: Select up to 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Religious, Political, Mythological, Historical, Indigenous, Pop culture, Folklore]. Please provide your output in the following format:  {'Color Palette': ['most associated label', ..., 'least associated label'],  'Subject Matter': ['most associated label', ..., 'least associated label'],  'Mood/Emotion': ['most associated label', ..., 'least associated label'], 'Style/Aesthetic': ['most associated label', ..., 'least associated label'],  'Setting/Location': ['most associated label', ..., 'least associated label'],  'Time Period': ['most associated label', ..., 'least associated label'],  'Cultural/Symbolic Representation': ['most associated label', ..., 'least associated label']}. If an attribute is not obvious, infer from the context of the description an attribute, don't use 'none' or 'not specified' as an attribute. Only select attribute values from the provided list of options. PLEASE DO NOT Assign any attribute that is not present in the pre-defined attributes. Format the output in double quotations so it can be converted into an object with json. The description is as follows:\" + description\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    attributes_content = response.choices[0].message.content\n",
    "    attributes_dict = json.loads(attributes_content)\n",
    "\n",
    "    return attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': ['Earthy', 'Vibrant', 'Muted'], 'Subject Matter': ['Nature', 'Landscape'], 'Mood/Emotion': ['Serene', 'Peaceful'], 'Style/Aesthetic': ['Realism'], 'Setting/Location': ['Forest', 'Countryside'], 'Time Period': ['Contemporary'], 'Cultural/Symbolic Representation': ['Folklore']}\n"
     ]
    }
   ],
   "source": [
    "print(description_to_attributes_predefined_two(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Quantify Comparison between two images to see which ones are closer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to determine Images that are overall closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_to_all_attributes(description):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a machine learning model trained to extract specific attributes from a detailed description of an image. Your task is to identify and select the most appropriate label from the following pre-defined set of attributes for each of the seven categories given below, and represent them as key-value pairs in a Python dictionary: 1. Color Palette: Select exaclty 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Vibrant, Monochromatic, Pastel, Earthy, Neon, Muted, Bold]. 2. Subject Matter: Select exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Landscape, Portrait, Still life, Abstract, Urban, Nature, Architecture]. 3. Mood/Emotion: Select exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Serene, Energetic, Melancholic, Joyful, Mysterious, Peaceful, Dramatic]. 4. Style/Aesthetic: Select exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Realism, Impressionism, Surrealism, Minimalism, Expressionism, Cubism, Romanticism]. 5. Setting/Location: Select exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Cityscape, Countryside, Beach, Forest, Mountains, Urban, Rural]. 6. Time Period: Select exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Contemporary, Renaissance, Medieval, Modern, Ancient, Futuristic, Victorian]. 7. Cultural/Symbolic Representation: Select Exactly 7 labels without repetition from only the following options, ordered from the most closely associated to the least associated with the image: [Religious, Political, Mythological, Historical, Indigenous, Pop culture, Folklore]. Please provide your output in the following format:  {'Color Palette': ['most associated label', ..., 'least associated label'],  'Subject Matter': ['most associated label', ..., 'least associated label'],  'Mood/Emotion': ['most associated label', ..., 'least associated label'], 'Style/Aesthetic': ['most associated label', ..., 'least associated label'],  'Setting/Location': ['most associated label', ..., 'least associated label'],  'Time Period': ['most associated label', ..., 'least associated label'],  'Cultural/Symbolic Representation': ['most associated label', ..., 'least associated label']}. If an attribute is not obvious, infer from the context of the description an attribute, don't use 'none' or 'not specified' as an attribute. Only select attribute values from the provided list of options. PLEASE DO NOT Assign any attribute that is not present in the pre-defined attributes. I repeat - no label in the result should be outside the predefined set of labels for each attribute. Format the output in double quotations so it can be converted into an object with json. The description is as follows:\" + description\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    attributes_content = response.choices[0].message.content\n",
    "    attributes_dict = json.loads(attributes_content)\n",
    "\n",
    "    return attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': ['Vibrant', 'Earthy', 'Muted', 'Pastel', 'Monochromatic', 'Bold', 'Neon'], 'Subject Matter': ['Nature', 'Landscape', 'Still life', 'Abstract', 'Urban', 'Portrait', 'Architecture'], 'Mood/Emotion': ['Peaceful', 'Serene', 'Joyful', 'Mysterious', 'Energetic', 'Melancholic', 'Dramatic'], 'Style/Aesthetic': ['Realism', 'Impressionism', 'Minimalism', 'Surrealism', 'Expressionism', 'Romanticism', 'Cubism'], 'Setting/Location': ['Forest', 'Countryside', 'Rural', 'Mountains', 'Beach', 'Urban', 'Cityscape'], 'Time Period': ['Contemporary', 'Modern', 'Futuristic', 'Medieval', 'Renaissance', 'Ancient', 'Victorian'], 'Cultural/Symbolic Representation': ['Indigenous', 'Historical', 'Folklore', 'Political', 'Mythological', 'Pop culture', 'Religious']}\n",
      "Color Palette 7\n",
      "Subject Matter 7\n",
      "Mood/Emotion 7\n",
      "Style/Aesthetic 7\n",
      "Setting/Location 7\n",
      "Time Period 7\n",
      "Cultural/Symbolic Representation 7\n"
     ]
    }
   ],
   "source": [
    "obj = description_to_all_attributes(description)\n",
    "print(obj)\n",
    "\n",
    "# print the length of the array for each attribute in the object\n",
    "\n",
    "for key, value in obj.items():\n",
    "    print(key, len(value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Manhattan Distance Based Method to quantify discimilarity between image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_ordering_discimilarity(arr1, arr2):\n",
    "\n",
    "    index_dict = {element: i for i, element in enumerate(arr2)}\n",
    "\n",
    "    # Calculate the sum of absolute distances\n",
    "    total_distance = 0\n",
    "    for i, element in enumerate(arr1):\n",
    "        index_in_array2 = index_dict[element]\n",
    "        distance = abs(i - index_in_array2)\n",
    "        total_distance += distance\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 2\n"
     ]
    }
   ],
   "source": [
    "array1 = ['a', 'b', 'c', 'd']\n",
    "array2 = ['b', 'a', 'c', 'd']\n",
    "similarity_score = array_ordering_discimilarity(array1, array2)\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Palette 7\n",
      "Subject Matter 7\n",
      "Mood/Emotion 7\n",
      "Style/Aesthetic 7\n",
      "Setting/Location 7\n",
      "Time Period 7\n",
      "Cultural/Symbolic Representation 7\n"
     ]
    }
   ],
   "source": [
    "test_obj = {\n",
    "  \"Color Palette\": [\"Vibrant\", \"Monochromatic\", \"Pastel\", \"Earthy\", \"Neon\", \"Muted\", \"Bold\"],\n",
    "  \"Subject Matter\": [\"Landscape\", \"Portrait\", \"Still life\", \"Abstract\", \"Urban\", \"Nature\", \"Architecture\"],\n",
    "  \"Mood/Emotion\": [\"Serene\", \"Energetic\", \"Melancholic\", \"Joyful\", \"Mysterious\", \"Peaceful\", \"Dramatic\"],\n",
    "  \"Style/Aesthetic\": [\"Realism\", \"Impressionism\", \"Surrealism\", \"Minimalism\", \"Expressionism\", \"Cubism\", \"Romanticism\"],\n",
    "  \"Setting/Location\": [\"Cityscape\", \"Countryside\", \"Beach\", \"Forest\", \"Mountains\", \"Urban\", \"Rural\"],\n",
    "  \"Time Period\": [\"Contemporary\", \"Renaissance\", \"Medieval\", \"Modern\", \"Ancient\", \"Futuristic\", \"Victorian\"],\n",
    "  \"Cultural/Symbolic Representation\": [\"Religious\", \"Political\", \"Mythological\", \"Historical\", \"Indigenous\", \"Pop culture\", \"Folklore\"]\n",
    "}\n",
    "\n",
    "for key, value in test_obj.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_labels_discimilarity(image_attributes, user_attributes):\n",
    "\n",
    "    total_distance = 0\n",
    "    \n",
    "    for key, value in image_attributes.items():\n",
    "\n",
    "        user_value = user_attributes[key]\n",
    "        distance = array_ordering_discimilarity(value, user_value)\n",
    "        total_distance += distance\n",
    "    \n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Distance: 86\n"
     ]
    }
   ],
   "source": [
    "test_distance = image_labels_discimilarity(test_obj, obj)\n",
    "print(\"Test Distance:\", test_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': ['Vibrant', 'Earthy', 'Pastel', 'Muted', 'Monochromatic', 'Bold', 'Neon'], 'Subject Matter': ['Landscape', 'Nature', 'Still life', 'Abstract', 'Urban', 'Architecture', 'Portrait'], 'Mood/Emotion': ['Serene', 'Peaceful', 'Joyful', 'Mysterious', 'Dramatic', 'Energetic', 'Melancholic'], 'Style/Aesthetic': ['Realism', 'Impressionism', 'Romanticism', 'Minimalism', 'Expressionism', 'Surrealism', 'Cubism'], 'Setting/Location': ['Mountains', 'Countryside', 'Forest', 'Rural', 'Beach', 'Cityscape', 'Urban'], 'Time Period': ['Contemporary', 'Modern', 'Victorian', 'Renaissance', 'Medieval', 'Ancient', 'Futuristic'], 'Cultural/Symbolic Representation': ['Historical', 'Indigenous', 'Folklore', 'Mythological', 'Religious', 'Political', 'Pop culture']}\n"
     ]
    }
   ],
   "source": [
    "test_url1 = \"https://upload.wikimedia.org/wikipedia/commons/e/e2/Lake_Tekapo_01.jpg\"\n",
    "test_url1_attributes = description_to_all_attributes(image_to_text(test_url1))\n",
    "print(test_url1_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Distance URL1: 92\n"
     ]
    }
   ],
   "source": [
    "test_distance_url1 = image_labels_discimilarity(test_url1_attributes, test_obj)\n",
    "print(\"Test Distance URL1:\", test_distance_url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': ['Earthy', 'Muted', 'Vibrant', 'Pastel', 'Bold', 'Monochromatic', 'Neon'], 'Subject Matter': ['Nature', 'Portrait', 'Landscape', 'Still life', 'Abstract', 'Urban', 'Architecture'], 'Mood/Emotion': ['Serene', 'Peaceful', 'Joyful', 'Dramatic', 'Mysterious', 'Energetic', 'Melancholic'], 'Style/Aesthetic': ['Realism', 'Romanticism', 'Impressionism', 'Minimalism', 'Expressionism', 'Surrealism', 'Cubism'], 'Setting/Location': ['Countryside', 'Mountains', 'Forest', 'Rural', 'Beach', 'Cityscape', 'Urban'], 'Time Period': ['Contemporary', 'Modern', 'Victorian', 'Renaissance', 'Medieval', 'Ancient', 'Futuristic'], 'Cultural/Symbolic Representation': ['Folklore', 'Historical', 'Mythological', 'Indigenous', 'Religious', 'Political', 'Pop culture']}\n"
     ]
    }
   ],
   "source": [
    "test_url2 = \"https://upload.wikimedia.org/wikipedia/commons/8/82/Найкращі_миті_життя.jpg\"\n",
    "test_url2_attributes = description_to_all_attributes(image_to_text(test_url2))\n",
    "print(test_url2_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Distance URL2: 100\n"
     ]
    }
   ],
   "source": [
    "test_distance_url2 = image_labels_discimilarity(test_url2_attributes, test_obj)\n",
    "print(\"Test Distance URL2:\", test_distance_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Color Palette': ['Monochromatic', 'Muted', 'Earthy', 'Vibrant', 'Bold', 'Pastel', 'Neon'], 'Subject Matter': ['Architecture', 'Urban', 'Landscape', 'Portrait', 'Still life', 'Abstract', 'Nature'], 'Mood/Emotion': ['Melancholic', 'Serene', 'Dramatic', 'Peaceful', 'Mysterious', 'Energetic', 'Joyful'], 'Style/Aesthetic': ['Realism', 'Minimalism', 'Expressionism', 'Surrealism', 'Romanticism', 'Impressionism', 'Cubism'], 'Setting/Location': ['Urban', 'Rural', 'Cityscape', 'Countryside', 'Forest', 'Mountains', 'Beach'], 'Time Period': ['Modern', 'Contemporary', 'Victorian', 'Medieval', 'Renaissance', 'Futuristic', 'Ancient'], 'Cultural/Symbolic Representation': ['Historical', 'Political', 'Indigenous', 'Folklore', 'Religious', 'Pop culture', 'Mythological']}\n"
     ]
    }
   ],
   "source": [
    "test_url3 = \"https://upload.wikimedia.org/wikipedia/commons/6/69/Russia._Industry_Orekhovo-Zuevo._img-004.jpg\"\n",
    "test_url3_attributes = description_to_all_attributes(image_to_text(test_url3))\n",
    "print(test_url3_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Distance URL3: 112\n"
     ]
    }
   ],
   "source": [
    "test_distance_url3 = image_labels_discimilarity(test_url3_attributes, test_obj)\n",
    "print(\"Test Distance URL3:\", test_distance_url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between test_url1 and test_url2: 32\n",
      "Disimilarity between test_url1 and test_url3: 102\n",
      "Disimilarity between test_url2 and test_url3: 98\n"
     ]
    }
   ],
   "source": [
    "dis_12 = image_labels_discimilarity(test_url1_attributes, test_url2_attributes)\n",
    "dis_13 = image_labels_discimilarity(test_url1_attributes, test_url3_attributes)\n",
    "dis_23 = image_labels_discimilarity(test_url2_attributes, test_url3_attributes)\n",
    "\n",
    "print(\"Disimilarity between test_url1 and test_url2:\", dis_12)\n",
    "print(\"Disimilarity between test_url1 and test_url3:\", dis_13)\n",
    "print(\"Disimilarity between test_url2 and test_url3:\", dis_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the above code into a function that does it all\n",
    "\n",
    "- Takes various images and calculates and plots them on a graph based on their dissimilairty distance.\n",
    "- Is able to take in uploaded images - not just wiki media URL - specifically the art images from our dataset.\n",
    "- It is able to calculate total dissimilarity and specific label discimilairty between images\n",
    "- more trouble-shooting so that the image-to-text to json works every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate dissimilarity for a specific label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dissimilarity(image_attributes, user_attributes, label):\n",
    "    \n",
    "    image_value = image_attributes.get(label)\n",
    "    user_value = user_attributes.get(label)\n",
    "    \n",
    "    \n",
    "    # Calculate the dissimilarity score between the two arrays\n",
    "    distance = array_ordering_discimilarity(image_value, user_value)\n",
    "    \n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between test_url1 and test_url2 for Color Palette: 8\n",
      "Disimilarity between test_url1 and test_url2 for Subject Matter: 12\n"
     ]
    }
   ],
   "source": [
    "dis_12_color = label_dissimilarity(test_url1_attributes, test_url2_attributes, \"Color Palette\")\n",
    "dis_12_subject = label_dissimilarity(test_url1_attributes, test_url2_attributes, \"Subject Matter\")\n",
    "\n",
    "print(\"Disimilarity between test_url1 and test_url2 for Color Palette:\", dis_12_color)\n",
    "print(\"Disimilarity between test_url1 and test_url2 for Subject Matter:\", dis_12_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Image dissimilarity functino with least dissimilar label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_labels_discimilarity_mod(image_attributes, user_attributes):\n",
    "    \n",
    "    distances = {}\n",
    "    total_distance = 0\n",
    "    \n",
    "    for key, value in image_attributes.items():\n",
    "        user_value = user_attributes.get(key)\n",
    "        \n",
    "        # If the user attribute is missing, skip\n",
    "        if user_value is None:\n",
    "            continue\n",
    "        \n",
    "        distance = array_ordering_discimilarity(value, user_value)\n",
    "        total_distance += distance\n",
    "        distances[key] = distance\n",
    "    \n",
    "    # Sort labels based on distances in ascending order\n",
    "    ordered_labels = sorted(distances, key=distances.get)\n",
    "    \n",
    "    return total_distance, ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between test_url1 and test_url2 (Modified): 32\n",
      "Ordered Labels: ['Time Period', 'Mood/Emotion', 'Style/Aesthetic', 'Setting/Location', 'Cultural/Symbolic Representation', 'Color Palette', 'Subject Matter']\n"
     ]
    }
   ],
   "source": [
    "dis_12_mod, label_12 = image_labels_discimilarity_mod(test_url1_attributes, test_url2_attributes)\n",
    "\n",
    "print(\"Disimilarity between test_url1 and test_url2 (Modified):\", dis_12_mod)\n",
    "print(\"Ordered Labels:\", label_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look into other metrics to quantify similairty between image labels\n",
    "### Potentially enhance attribute list for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_url_1 = \"https://upload.wikimedia.org/wikipedia/commons/0/0d/Great_Wave_off_Kanagawa2.jpg\"\n",
    "art_url_2 = \"https://upload.wikimedia.org/wikipedia/commons/9/94/The_Nightwatch_by_Rembrandt_-_Rijksmuseum.jpg\"\n",
    "art_url_3 = \"https://upload.wikimedia.org/wikipedia/commons/b/b6/Sebastiano_Ricci_002.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes for Art URL 1: {'Color Palette': ['Vibrant', 'Muted', 'Bold', 'Monochromatic', 'Earthy', 'Pastel', 'Neon'], 'Subject Matter': ['Nature', 'Abstract', 'Portrait', 'Landscape', 'Still life', 'Urban', 'Architecture'], 'Mood/Emotion': ['Dramatic', 'Mysterious', 'Serene', 'Energetic', 'Melancholic', 'Peaceful', 'Joyful'], 'Style/Aesthetic': ['Realism', 'Expressionism', 'Surrealism', 'Impressionism', 'Romanticism', 'Minimalism', 'Cubism'], 'Setting/Location': ['Beach', 'Mountains', 'Countryside', 'Forest', 'Rural', 'Cityscape', 'Urban'], 'Time Period': ['Ancient', 'Modern', 'Contemporary', 'Medieval', 'Renaissance', 'Victorian', 'Futuristic'], 'Cultural/Symbolic Representation': ['Historical', 'Mythological', 'Folklore', 'Indigenous', 'Religious', 'Political', 'Pop culture']}\n"
     ]
    }
   ],
   "source": [
    "text_1 = image_to_text(art_url_1)\n",
    "attributes_1 = description_to_all_attributes(text_1)\n",
    "\n",
    "print(\"Attributes for Art URL 1:\", attributes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between Art URL 1 and test object: 104\n"
     ]
    }
   ],
   "source": [
    "# testing against test object\n",
    "\n",
    "dis_1 = image_labels_discimilarity(attributes_1, test_obj)\n",
    "print(\"Disimilarity between Art URL 1 and test object:\", dis_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes for Art URL 2: {'Color Palette': ['Bold', 'Muted', 'Vibrant', 'Monochromatic', 'Earthy', 'Pastel', 'Neon'], 'Subject Matter': ['Portrait', 'Urban', 'Abstract', 'Still life', 'Landscape', 'Nature', 'Architecture'], 'Mood/Emotion': ['Dramatic', 'Mysterious', 'Energetic', 'Serene', 'Melancholic', 'Peaceful', 'Joyful'], 'Style/Aesthetic': ['Realism', 'Romanticism', 'Expressionism', 'Impressionism', 'Surrealism', 'Cubism', 'Minimalism'], 'Setting/Location': ['Urban', 'Cityscape', 'Countryside', 'Beach', 'Forest', 'Mountains', 'Rural'], 'Time Period': ['Renaissance', 'Victorian', 'Medieval', 'Modern', 'Contemporary', 'Ancient', 'Futuristic'], 'Cultural/Symbolic Representation': ['Historical', 'Political', 'Religious', 'Folklore', 'Mythological', 'Indigenous', 'Pop culture']}\n"
     ]
    }
   ],
   "source": [
    "text_2 = image_to_text(art_url_2)\n",
    "attributes_2 = description_to_all_attributes(text_2)\n",
    "\n",
    "print(\"Attributes for Art URL 2:\", attributes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between Art URL 2 and test object: 96\n"
     ]
    }
   ],
   "source": [
    "# testing against test object\n",
    "\n",
    "dis_2 = image_labels_discimilarity(attributes_2, test_obj)\n",
    "print(\"Disimilarity between Art URL 2 and test object:\", dis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes for Art URL 3: {'Color Palette': ['Muted', 'Earthy', 'Pastel', 'Vibrant', 'Monochromatic', 'Bold', 'Neon'], 'Subject Matter': ['Portrait', 'Still life', 'Architecture', 'Nature', 'Abstract', 'Urban', 'Landscape'], 'Mood/Emotion': ['Serene', 'Peaceful', 'Dramatic', 'Mysterious', 'Melancholic', 'Joyful', 'Energetic'], 'Style/Aesthetic': ['Realism', 'Romanticism', 'Impressionism', 'Expressionism', 'Surrealism', 'Minimalism', 'Cubism'], 'Setting/Location': ['Rural', 'Countryside', 'Cityscape', 'Urban', 'Forest', 'Mountains', 'Beach'], 'Time Period': ['Renaissance', 'Victorian', 'Modern', 'Medieval', 'Contemporary', 'Ancient', 'Futuristic'], 'Cultural/Symbolic Representation': ['Religious', 'Historical', 'Mythological', 'Folklore', 'Political', 'Indigenous', 'Pop culture']}\n"
     ]
    }
   ],
   "source": [
    "text_3 = image_to_text(art_url_3)\n",
    "attributes_3 = description_to_all_attributes(text_3)\n",
    "\n",
    "print(\"Attributes for Art URL 3:\", attributes_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between Art URL 3 and test object: 102\n"
     ]
    }
   ],
   "source": [
    "# testing against test object\n",
    "\n",
    "dis_3 = image_labels_discimilarity(attributes_3, test_obj)\n",
    "print(\"Disimilarity between Art URL 3 and test object:\", dis_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disimilarity between Art URL 1 and Art URL 2: 78\n",
      "Disimilarity between Art URL 1 and Art URL 3: 102\n",
      "Disimilarity between Art URL 2 and Art URL 3: 74\n",
      "Disimilarity between Art URL 1 and Art URL 2 (Modified): 78\n",
      "Ordered Labels: ['Mood/Emotion', 'Color Palette', 'Style/Aesthetic', 'Cultural/Symbolic Representation', 'Subject Matter', 'Time Period', 'Setting/Location']\n",
      "Disimilarity between Art URL 2 and Art URL 3 (Modified): 74\n",
      "Ordered Labels: ['Time Period', 'Style/Aesthetic', 'Cultural/Symbolic Representation', 'Color Palette', 'Setting/Location', 'Subject Matter', 'Mood/Emotion']\n"
     ]
    }
   ],
   "source": [
    "dis_art1_art2 = image_labels_discimilarity(attributes_1, attributes_2)\n",
    "dis_art1_art3 = image_labels_discimilarity(attributes_1, attributes_3)\n",
    "dis_art2_art3 = image_labels_discimilarity(attributes_2, attributes_3)\n",
    "\n",
    "print(\"Disimilarity between Art URL 1 and Art URL 2:\", dis_art1_art2)\n",
    "print(\"Disimilarity between Art URL 1 and Art URL 3:\", dis_art1_art3)\n",
    "print(\"Disimilarity between Art URL 2 and Art URL 3:\", dis_art2_art3)\n",
    "\n",
    "dis_art1_art2_mod, label_art1_art2 = image_labels_discimilarity_mod(attributes_1, attributes_2)\n",
    "\n",
    "print(\"Disimilarity between Art URL 1 and Art URL 2 (Modified):\", dis_art1_art2_mod)\n",
    "print(\"Ordered Labels:\", label_art1_art2)\n",
    "\n",
    "dis_art2_art3_mod, label_art2_art3 = image_labels_discimilarity_mod(attributes_2, attributes_3)\n",
    "\n",
    "print(\"Disimilarity between Art URL 2 and Art URL 3 (Modified):\", dis_art2_art3_mod)\n",
    "print(\"Ordered Labels:\", label_art2_art3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERY IMPORTANT: ENSURING THAT THE LABEL ORDERING FOR EACH IMAGE ONLY CONTAINS LABELS FROM PRE_DEFINED SET OF LABELS. RUN ABOVE CODE CELL TO UNDERSATND MORE ABOUT THIS ERROR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
