{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                filename           artist  \\\n",
      "0      Abstract_Expressionism/aaron-siskind_acolman-1...    aaron siskind   \n",
      "1      Abstract_Expressionism/aaron-siskind_chicago-6...    aaron siskind   \n",
      "2      Abstract_Expressionism/aaron-siskind_glouceste...    aaron siskind   \n",
      "3      Abstract_Expressionism/aaron-siskind_jerome-ar...    aaron siskind   \n",
      "4      Abstract_Expressionism/aaron-siskind_kentucky-...    aaron siskind   \n",
      "...                                                  ...              ...   \n",
      "80037  Impressionism/edgar-degas_portrait-of-mary-cas...      edgar degas   \n",
      "80038  High_Renaissance/giorgione_portrait-of-a-venet...        giorgione   \n",
      "80039  High_Renaissance/titian_portrait-of-a-venetian...           titian   \n",
      "80040  High_Renaissance/pinturicchio_riconciliazione-...     pinturicchio   \n",
      "80041  High_Renaissance/luca-signorelli_coriolanus-pe...  luca signorelli   \n",
      "\n",
      "                            genre  \\\n",
      "0      ['Abstract Expressionism']   \n",
      "1      ['Abstract Expressionism']   \n",
      "2      ['Abstract Expressionism']   \n",
      "3      ['Abstract Expressionism']   \n",
      "4      ['Abstract Expressionism']   \n",
      "...                           ...   \n",
      "80037           ['Impressionism']   \n",
      "80038        ['High Renaissance']   \n",
      "80039        ['High Renaissance']   \n",
      "80040        ['High Renaissance']   \n",
      "80041        ['High Renaissance']   \n",
      "\n",
      "                                             description             phash  \\\n",
      "0                                         acolman-1-1955  bebbeb018a7d80a8   \n",
      "1                                         chicago-6-1961  d7d0781be51fc00e   \n",
      "2                                    gloucester-16a-1944  9f846e5a6c639325   \n",
      "3                                    jerome-arizona-1949  a5d691f85ac5e4d0   \n",
      "4                                        kentucky-4-1951  880df359e6b11db1   \n",
      "...                                                  ...               ...   \n",
      "80037                           portrait-of-mary-cassatt  fc8d8c9c49e15365   \n",
      "80038           portrait-of-a-venetian-gentleman-1510(2)  fcfc9b330325708c   \n",
      "80039                 portrait-of-a-venetian-nobleman(1)  fcfc9b330325708c   \n",
      "80040                  riconciliazione-di-coriolano-1509  fef3438ca0d605e1   \n",
      "80041  coriolanus-persuaded-by-his-family-to-spare-ro...  fef3438ca0d605e1   \n",
      "\n",
      "       width  height  genre_count            subset  \n",
      "0       1922    1382            1             train  \n",
      "1       1382    1746            1             train  \n",
      "2       1382    1857            1             train  \n",
      "3       1382    1849            1             train  \n",
      "4       1382    1625            1             train  \n",
      "...      ...     ...          ...               ...  \n",
      "80037   1382    1756            1  uncertain artist  \n",
      "80038   1382    1645            1  uncertain artist  \n",
      "80039   1382    1645            1  uncertain artist  \n",
      "80040   1382    1412            1  uncertain artist  \n",
      "80041   1382    1412            1  uncertain artist  \n",
      "\n",
      "[80042 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"wikiart_full.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style: Abstract_Expressionism       # of Pieces: 2594\n",
      "Style: Art_Nouveau_Modern           # of Pieces: 4168\n",
      "Style: Baroque                      # of Pieces: 4236\n",
      "Style: Cubism                       # of Pieces: 2177\n",
      "Style: Expressionism                # of Pieces: 6335\n",
      "Style: Impressionism                # of Pieces: 13028\n",
      "Style: Naive_Art_Primitivism        # of Pieces: 2385\n",
      "Style: Northern_Renaissance         # of Pieces: 2551\n",
      "Style: Post_Impressionism           # of Pieces: 6307\n",
      "Style: Realism                      # of Pieces: 10546\n",
      "Style: Rococo                       # of Pieces: 2087\n",
      "Style: Romanticism                  # of Pieces: 6919\n",
      "Style: Symbolism                    # of Pieces: 4524\n"
     ]
    }
   ],
   "source": [
    "# Group art by type\n",
    "all_grouped_art = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    filename = row[\"filename\"]\n",
    "    art_style = filename[:filename.index('/')]\n",
    "    \n",
    "    if art_style not in all_grouped_art:\n",
    "        all_grouped_art[art_style] = []\n",
    "    all_grouped_art[art_style].append(row)\n",
    "\n",
    "for key, value in all_grouped_art.items():\n",
    "    if len(value) > 2000:\n",
    "        print(str.ljust(f\"Style: {key}\", 35),  f\"# of Pieces: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with only art we care about\n",
    "train_styles = [\"Abstract_Expressionism\", \"Art_Nouveau_Modern\", \"Cubism\", \"Impressionism\", \"Naive_Art_Primitivism\"]\n",
    "grouped_art = {}\n",
    "\n",
    "for key, value in all_grouped_art.items():\n",
    "    if key in train_styles:\n",
    "        grouped_art[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wikiart_images/Abstract_Expressionism'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     my_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikiart_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(my_path):\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m train_styles:\n\u001b[1;32m      8\u001b[0m     my_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wikiart_images/Abstract_Expressionism'"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "for dir in train_styles:\n",
    "    my_path = f\"wikiart_images/{dir}\"\n",
    "    if not os.path.exists(my_path):\n",
    "        os.mkdir(my_path)\n",
    "\n",
    "for dir in train_styles:\n",
    "    my_path = f\"train_images/{dir}\"\n",
    "    if not os.path.exists(my_path):\n",
    "        os.mkdir(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total width:  40362626\n",
      "Total height:  39613336\n",
      "Average width/height ratio:  1.0189150946539822\n"
     ]
    }
   ],
   "source": [
    "# Find average image size\n",
    "total_width, total_height = 0, 0\n",
    "for art_pieces in grouped_art.values():\n",
    "    for art_piece in art_pieces:\n",
    "        total_width += art_piece[\"width\"]\n",
    "        total_height += art_piece[\"height\"]\n",
    "\n",
    "print(\"Total width: \", total_width)\n",
    "print(\"Total height: \", total_height)\n",
    "avg_width_height_ratio = total_width / total_height\n",
    "print(\"Average width/height ratio: \", avg_width_height_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWidthHeightRatio(df_row):\n",
    "    width = df_row[\"width\"]\n",
    "    height = df_row[\"height\"]\n",
    "    return width / height\n",
    "\n",
    "def withinEpsilon(num1, num2, epsilon):\n",
    "    return abs(num1 - num2) <= epsilon\n",
    "\n",
    "def imageNearAverageShape(df_row, ratio, epsilon):\n",
    "    width_height_ratio = getWidthHeightRatio(df_row)\n",
    "    return withinEpsilon(width_height_ratio, ratio, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m art_piece \u001b[38;5;129;01min\u001b[39;00m all_art:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimageNearAverageShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mart_piece\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     15\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m counters\u001b[38;5;241m.\u001b[39mappend(counter)\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mimageNearAverageShape\u001b[0;34m(df_row, ratio, epsilon)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimageNearAverageShape\u001b[39m(df_row, ratio, epsilon):\n\u001b[0;32m---> 10\u001b[0m     width_height_ratio \u001b[38;5;241m=\u001b[39m \u001b[43mgetWidthHeightRatio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_row\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m withinEpsilon(width_height_ratio, ratio, epsilon)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mgetWidthHeightRatio\u001b[0;34m(df_row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetWidthHeightRatio\u001b[39m(df_row):\n\u001b[1;32m      2\u001b[0m     width \u001b[38;5;241m=\u001b[39m df_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     height \u001b[38;5;241m=\u001b[39m \u001b[43mdf_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m width \u001b[38;5;241m/\u001b[39m height\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find the epsilon and width/height ratio which give us at least 1000 usable images from each style\n",
    "epsilon = 0.01\n",
    "\n",
    "found = False\n",
    "while not found:\n",
    "    # print(\"epsilon = \", epsilon)\n",
    "    ratio = 0.2\n",
    "    while ratio < 2:\n",
    "        # print(\"Ratio = \", ratio)\n",
    "        counters = []\n",
    "        for art_style, all_art in grouped_art.items():\n",
    "            counter = 0\n",
    "            for art_piece in all_art:\n",
    "                if imageNearAverageShape(art_piece, ratio, epsilon):\n",
    "                    counter += 1\n",
    "            counters.append(counter)\n",
    "        # print(counters)\n",
    "        if all(count >= 1000 for count in counters):\n",
    "            print(f\"Images within ratio, epsilon: {ratio}, {epsilon}\")\n",
    "            found = True\n",
    "        ratio += 0.01\n",
    "    epsilon += 0.01\n",
    "\n",
    "# print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1000 images from each art style to dictionary\n",
    "# All images must have a width/height ratio within epsilon of 0.79\n",
    "ratio = 0.79\n",
    "epsilon = 0.15\n",
    "\n",
    "# Save all images which fit proper ratio\n",
    "train_images = {}\n",
    "for art_style, all_art_of_style in grouped_art.items():\n",
    "    art_pieces = all_art_of_style.copy()\n",
    "    random.shuffle(art_pieces)\n",
    "    train_images[art_style] = []\n",
    "    for art_piece in art_pieces:\n",
    "        if imageNearAverageShape(art_piece, ratio, epsilon):\n",
    "            train_images[art_style].append(art_piece)\n",
    "\n",
    "# Reduce # of images to 1000 per each style\n",
    "for art_style, art_images in train_images.items():\n",
    "    # train_images[art_style] = train_images[art_style][:1000]\n",
    "    short_training_images = []\n",
    "    for art_piece in train_images[art_style]:\n",
    "        piece_filename = art_piece[\"filename\"]\n",
    "        wikiart_path = \"wikiart_images/\" + piece_filename\n",
    "        if len(short_training_images) == 1000:\n",
    "            break\n",
    "        # Some images have weird path names with characters that break the path. This is\n",
    "        # an easy way of handling that case - simply skipping to the next image\n",
    "        if os.path.exists(wikiart_path):\n",
    "            short_training_images.append(art_piece)\n",
    "    train_images[art_style] = short_training_images\n",
    "\n",
    "    # print(len(train_images[art_style]))\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./train_images/train_images_dict.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m----> 2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mtrain_images\u001b[49m, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "with open('./train_images/train_images_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_images, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the images from the train dictionary to the train directory\n",
    "\n",
    "# Clear the train_images directories of any old training images\n",
    "for style in train_styles:\n",
    "    files = glob.glob(f\"train_images/{style}/*\")\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "# Move each image from the wikiart_images directory to the train_images directory\n",
    "for art_style, art_pieces in train_images.items():\n",
    "    for art_piece in art_pieces:\n",
    "        piece_filename = art_piece[\"filename\"]\n",
    "        wikiart_path = \"wikiart_images/\" + piece_filename\n",
    "        train_path = \"train_images/\" + piece_filename\n",
    "        shutil.copy(wikiart_path, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretchImage(image_path, new_width, new_height):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image\n",
    "    stretched_image = image.resize((new_width, new_height))\n",
    "    \n",
    "    # Save the stretched image\n",
    "    stretched_image.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing or stretching all train images to width = 100, height = 127\n",
      "Recommend width/height = 0.79. Your width/height ratio = 0.7874015748031497\n"
     ]
    }
   ],
   "source": [
    "# You can make width and height whatever you want, but recommend width/height ratio = 0.79\n",
    "width = 100\n",
    "height = 127\n",
    "\n",
    "print(f\"Compressing or stretching all train images to width = {width}, height = {height}\")\n",
    "print(f\"Recommend width/height = {ratio}. Your width/height ratio = {width / height}\")\n",
    "\n",
    "# Compress the images to fit your own width and size\n",
    "for art_style, art_pieces in train_images.items():\n",
    "    for art_piece in art_pieces:\n",
    "        piece_filename = art_piece[\"filename\"]\n",
    "        train_path = \"train_images/\" + piece_filename\n",
    "        stretchImage(train_path, width, height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Only cells below it - for TARU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_style = {}\n",
    "\n",
    "def hashNPArray(arr):\n",
    "    return hash(arr.tobytes())\n",
    "\n",
    "def setImgStyle(img, style):\n",
    "    img = hashNPArray(img)\n",
    "    img_to_style[img] = style\n",
    "\n",
    "def getImgStyle(img):\n",
    "    img = hashNPArray(img)\n",
    "    return img_to_style[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_images/train_images_dict.pickle', 'rb') as handle:\n",
    "    train_images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainData(batch_size=32, random_order=True, train=True):\n",
    "    dataset = []\n",
    "    batch_counter = 0\n",
    "    batch = []\n",
    "\n",
    "    train_images_path = \"./train_images/\"\n",
    "\n",
    "    train_pieces = []\n",
    "    for style, art_pieces in train_images.items():\n",
    "        for piece in art_pieces:\n",
    "            # print(piece)\n",
    "            # setImgStyle(piece, style)\n",
    "            train_pieces.append(piece)\n",
    "    \n",
    "    if random_order:\n",
    "        random.shuffle(train_pieces)\n",
    "\n",
    "    width = 100\n",
    "    height = 127\n",
    "\n",
    "    # for style in train_styles:\n",
    "    #     style_dir = train_images_path + style + \"/\"\n",
    "    #     for file in tqdm(os.listdir(style_dir)):\n",
    "\n",
    "    for art_piece in tqdm(train_pieces):\n",
    "        # print(art_piece)  \n",
    "        img = Image.open(train_images_path + art_piece[\"filename\"])\n",
    "        img = np.asarray(img).reshape(3, height, width)\n",
    "        \n",
    "        filename = art_piece[\"filename\"]\n",
    "        art_style = filename[:filename.index('/')]\n",
    "\n",
    "        setImgStyle(img, art_style)\n",
    "\n",
    "        if batch_counter < batch_size:\n",
    "            batch.append(img)\n",
    "            batch_counter += 1\n",
    "        else:\n",
    "            dataset.append(np.array(batch))\n",
    "            batch = []\n",
    "            batch_counter = 0\n",
    "\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 8018.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape without random order:  (151, 32, 3, 127, 100)\n",
      "First image should be Abstract Expresisonism, it is:  Abstract_Expressionism\n",
      "320th image should be Impressionism, it is:  Impressionism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 8538.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape with random order:  (151, 32, 3, 127, 100)\n",
      "First image is:  Impressionism\n",
      "320th image is:  Abstract_Expressionism\n"
     ]
    }
   ],
   "source": [
    "dataset = loadTrainData(batch_size=32, random_order=False, train=True)\n",
    "\n",
    "print(\"Dataset Shape without random order: \", np.shape(dataset))\n",
    "# print(np.shape(dataset[0][0]))\n",
    "print(\"First image should be Abstract Expresisonism, it is: \", getImgStyle(dataset[0][0]))\n",
    "print(\"320th image should be Impressionism, it is: \", getImgStyle(dataset[100][0]))\n",
    "\n",
    "dataset = loadTrainData(batch_size=32, random_order=True, train=True)\n",
    "\n",
    "print(\"Dataset Shape with random order: \", np.shape(dataset))\n",
    "# print(np.shape(dataset[0][0]))\n",
    "print(\"First image is: \", getImgStyle(dataset[0][0]))\n",
    "print(\"320th image is: \", getImgStyle(dataset[100][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
